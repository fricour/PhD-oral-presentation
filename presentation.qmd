---
format: 
  revealjs:
    #chalkboard: true
    #theme: dark
    transition: slide 
    slide-number: c
    #embed-resources: true
    progress: true
    theme: [default, custom.scss]
    margin: 0.1
    width: 1200
    #smaller: true 
editor: visual
from: markdown+emoji
execute: 
  cache: true # need to put it to false when there is an update of data WITHOUT a change of code
---

```{r, libraries + wordcloud, echo = F, include=F}
# 
# # Load the required packages
#library(tm)
library(wordcloud)
library(quarto)
library(plotly)
library(tidyverse)
library(echarts4r)
library(tibble)
library(latex2exp)
library(htmlwidgets)
library(htmltools)
library(highcharter)
library(visNetwork)
library(reactablefmtr)
library(kableExtra)
library(ggplot2)
library(webshot2)
library(formattable)
library(lubridate)
library(flextable)
library(cmocean)
library(scales)
library(patchwork)
library(viridis)
library(oce)
library(cowplot)
library(RColorBrewer)
library(vroom)
library(castr)
library(reactablefmtr)
library(gt)
library(spatialrisk)
library(ggOceanMaps)
library(gtExtras)
library(magick)
library(purrr)
library(RcppCNPy)

Sys.setlocale("LC_TIME", "en_GB.utf8")

# 
# # Set the path to your PDF file
# pdf_path <- "/home/flo/Downloads/RICOUR_FLORIAN_280323.pdf"
# 
# # Create a Corpus object from the PDF file
# my_corpus <- Corpus(URISource(pdf_path), readerControl = list(reader = readPDF))
# 
# # Convert the corpus to plain text
# my_corpus <- tm_map(my_corpus, PlainTextDocument)
# 
# # Remove numbers and punctuation
# my_corpus <- tm_map(my_corpus, removeNumbers)
# my_corpus <- tm_map(my_corpus, removePunctuation)
# 
# # Convert to lowercase
# my_corpus <- tm_map(my_corpus, content_transformer(tolower))
# 
# # Remove stopwords
# my_corpus <- tm_map(my_corpus, removeWords, stopwords("english"))
# 
# # Create a term-document matrix
# tdm <- TermDocumentMatrix(my_corpus)
# 
# # Convert the term-document matrix to a frequency matrix
# freq <- as.matrix(tdm)
# 
# # Sort the frequency matrix in descending order
# freq <- sort(rowSums(freq), decreasing = TRUE)
# 
# # Create a word cloud
# wordcloud(names(freq), freq, min.freq = 10, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
# 
# tmp <- as.data.frame(freq)
# tmp$word <- rownames(tmp)
# rownames(tmp) <- NULL
# vroom::vroom_write(tmp, file = "wordcloud.csv")
# wordcloud_df <- vroom::vroom('wordcloud.csv')
# #wordcloud(wordcloud_df$word, wordcloud_df$freq, min.freq = 10, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
# 
# 
# wordcloud_df <- wordcloud_df |> filter(freq >= 10) |> mutate(color = 'gray')
# wordcloud_df[wordcloud_df$word == 'bgcargo',]$word <- 'BGC-Argo'
# wordcloud_df[wordcloud_df$word == 'uvp',]$word <- 'UVP'
# wordcloud_df[wordcloud_df$word == 'poc',]$word <- 'POC'
# wordcloud_df[wordcloud_df$word == 'doc',]$word <- 'DOC'
# wordcloud_df[wordcloud_df$word == 'converse',]$word <- 'CONVERSE'
# wordcloud_df <- wordcloud_df |> filter(word != c('httpsdoiorg'))
# wordcloud_df[wordcloud_df$word %in% c('UVP', 'detritus', 'model', 'classification', 'classes', 'class','zooplankton'),]$color <- '#1B9E77'
# wordcloud_df[wordcloud_df$word %in% c('carbon', 'global', 'ocean','biological', 'pump', 'pumps', 'particles'),]$color <- 'black'
# wordcloud_df[wordcloud_df$word %in% c('CONVERSE','fluxes', 'flux', 'export', 'sequestration'),]$color <- '#D95F02'
# wordcloud_df[wordcloud_df$word %in% c('floats', 'size','BGC-Argo','concentrations', 'data', 'POC', 'particle'),]$color <- '#7570B3'
# 
# #wordcloud(wordcloud_df$word, wordcloud_df$freq, min.freq = 10, random.order = FALSE, colors = brewer.pal(8, "Dark2"), ordered.colors = T)
# #hchart(wordcloud_df, "wordcloud", hcaes(name = word, weight = freq))
# 
# 
# wc <- wordcloud_df |> 
#     #e_color_range(freq, color) |> 
#     e_charts(renderer = 'svg') |> 
#     e_cloud(word, freq, color, shape = "circle", sizeRange = c(5, 100)) 
# 
# htmlwidgets::saveWidget(widget = wc, file = "wc.html")
# #webshot('wc.html', file = 'images/wc.pdf')
# webshot('wc.html', file = 'images/wc2.pdf')
```

::: {style="text-align:center;"}
![](images/wc-cropped.svg){width="800" height="600"}
:::

# Introduction {background-color="black"}

## Dissolved inorganic carbon (DIC) {.smaller}

::: columns
::: {.column width="50%"}
```{r DIC}

library(echarts4r)
library(tibble)

# create data frame with parent-child relationships and node values
# df <- tibble(
#   parents = c("", "Everything", "Everything", "CO2 (aq)", "CO2 (aq)", "CO2 (aq)"), 
#   labels = c("Everything", "CO2 (aq)", "CO2 (gas)", "carbonic acid", "carbonate", "bicarbonate"), 
#   value = c(0, 50, 50, 0.25,5.25,44.5)
# )

# df <- tibble(
#   parents = c("", "Everything", "Everything", "ocean", "ocean", "ocean"),
#   labels = c("Everything", "ocean", "atmosphere", "carbonic acid", "carbonate", "bicarbonate"),
#   value = c(0, 50, 50, 0.25,5.25,44.5)
# )
# 
# # create a tree object
# df <- data.tree::FromDataFrameNetwork(df) 


df <- tibble(
  name = c("CO\u2082 (aq)", "CO\u2082 (gas)"),
  value = c(50,50),
  # 1st level
  itemStyle = tibble(color = c("#001852", "#e01f54")),
  children = list(
    tibble(
      #name = c("carbonic acid", "carbonate", "bicarbonate"),
      name = c("H\u2082CO\u2083", "CO\u2083\u00B2\u207B", "HCO\u2083\u207B"),
      value = c(0.25,5.25,44.5)
    ),
    NULL # atmosphere
  )
)

myStyles <- c(list(color = "#3F517D")) # custom styles defined
myNames <- list(c("carbonic acid", "carbonate", "bicarbonate")) # names to style
#myNames <- c("H\u2082CO\u2083", paste0("CO\u2083", "\u00B2\u207B"), paste0("HCO\u2083", "\u207B"))
myNames <- list(c("H\u2082CO\u2083", "CO\u2083\u00B2\u207B", "HCO\u2083\u207B"))
myLevels <- list(2) # hierarchical levels to style

# plot sunburst
df |>
  e_charts(renderer = "svg") |>
  #e_sunburst() 
  e_sunburst(myStyles, myNames, myLevels) |>
  e_labels(fontSize = 15)

```
:::

::: {.column width="50%"}
<!-- ::: {style="position:absolute;top:42.5%;right:10f;"} -->

```{=tex}
<!-- \begin{gather*} -->
<!-- DIC = CO_{2_{(aq)}} + H_{2}CO_{3} + HCO_{3}^{-} + CO_{3}^{2-}  -->
<!-- \end{gather*} -->
```
```{r ttt}
# df <- tibble(group = rep('DIC', 4),
#               name = c("CO\u2082 (aq)", "H\u2082CO\u2083", paste0("CO\u2083", "\u00B2\u207B"), paste0("HCO\u2083", "\u207B")),
#               value = c(0.25,0.25,10.5,89))

df <- tibble(group = rep('DIC', 3),
              name = c("CO\u2082*", paste0("CO\u2083", "\u00B2\u207B"), paste0("HCO\u2083", "\u207B")),
              value = c(0.5,10.5,89))

# hc <- hchart(df, "packedbubble", hcaes(name = name, value = value, group = group))
# hc |> hc_tooltip(
#     useHTML = TRUE,
#     pointFormat = "<b>{point.name}:</b> {point.value}"
#   ) |>
#   hc_plotOptions(
#     packedbubble = list(
#       maxSize = "200%",
#       minSize = "2%",
#       zMin = 10,
#       layoutAlgorithm = list(
#         gravitationalConstant =  0.05,
#         splitSeries =  FALSE, # TRUE to group points
#         seriesInteraction = FALSE,
#         dragBetweenSeries = FALSE,
#         parentNodeLimit = FALSE
#       ),
#       dataLabels = list(
#         enabled = TRUE,
#         #format = "{point.name}",
#         format = "<span style='font-size: 25px'>{point.name}</span>",
#         # formatter = JS(
#         #   "function() {
#         #     var r = this.point.z;
#         #     var fontSize = Math.round(10 + Math.sqrt(r));
#         #     return '<span style=\"font-size:' + fontSize + 'px; color:black; text-outline:none; font-weight:normal\">' + this.point.name + '</span>';
#         #   }"
#         # ),
#         filter = list(
#           property = "y",
#           operator = ">",
#           value = .5
#         )
#       ),
#       style = list(
#           color = "black",
#           textOutline = "none",
#           fontWeight = "normal"
#       )
#   )
# )

df |> 
  e_charts(name, renderer = 'svg') |> 
  e_pie(value, radius = c('35%', "70%"),
        #color = c("#FF6384", "#36A2EB", "#FFCE56"),
        color = c('#f2d643', '#ffb248', '#eb8146'),
        label = list(fontSize = 20, formatter = "{b} ({d}%)")) |>
  # e_title(
  #   "DIC",
  #   textStyle = list(
  #     fontSize = 36,
  #     fontWeight = "normal",
  #     color = "#333",
  #     textAlign = "center",
  #     textBaseline = "middle"
  #   ),
  #   top = "46%",
  #   left = "44%"
  # ) |>
  e_legend(F) 
```
:::
:::

## \> 200 Î¼mol/kg DIC gradient {.smaller}

```{r DIC distribution}

DIC_data <- vroom::vroom('../THESIS//DATA/GLODAP/DIC_distribution.csv')

# https://stackoverflow.com/questions/12514612/how-to-annotate-ggplot-with-latex
#ggplot(DIC_data, aes(y = mids, x = mean_DIC)) + geom_path(size = 1) + scale_y_reverse() + ylab('Depth (m)') + xlab(TeX('DIC ($\\mu$mol kg$^{-1}$)')) + theme_bw() 
plot_ly(DIC_data, x = ~mean_DIC, y = ~mids, type = 'scatter', mode = 'lines', color = I('#001852')) |>
   layout(xaxis = list(title = 'DIC (&mu;mol kg<sup>-1</sup>)', tickfont = list(size = 20), titlefont = list(size = 20)), yaxis = list(title = list(text = 'Depth (m)', standoff = 15L), autorange="reversed", tickfont = list(size = 20), titlefont = list(size = 20))) |> config(displayModeBar = FALSE)

#DIC_data |> e_charts(mean_DIC) |> e_line(mids)
#DIC_data |> e_charts(mean_DIC) |> e_line(mids) |> e_axis(mean_DIC, margin = 0) |> e_axis_labels(x = 'DIC (&mu;mol kg<sup>-1</sup>)', y = "")
```

::: footer
Source of data: GLODAPv2
:::

## Pumps acting against DIC mixing {.smaller}

::: columns
::: {.column width="50%"}
```{r, sankey chart for pumps}

# df <- tibble(root = 'DIC gradient', pump = c(rep('Solubility pump',1), rep('Biological carbon pump',7), rep('carbonate pump',2)))
# 
# hchart(data_to_sankey(df), "sankey", name = "diamonds")

# df <- tibble(
#   parents = c("", "Everything", "Everything", "Everything", "biological"),
#   labels = c("Everything", "solubility", "biological", "carbonate", "gravitational"),
#   value = c(0, 10, 70, 30, 70)
# )
# 
# # create a tree object
# df <- data.tree::FromDataFrameNetwork(df) 

# # plot sunburst
# df |>
#   e_charts(renderer = "svg") |>
#   e_sunburst() |> 
#   e_theme_custom('qualitative_palette.json')
#   #e_theme('tech-blue')

df <- tibble(
  name = c("solubility", "biological", "carbonate"),
  value = c(10,70,20),
  # 1st level
  itemStyle = tibble(color = c("#f5e8c8", "#001852", "#e01f54")),
  children = list(
    NULL,
    # tibble(
    #   name = c("gravitational"),
    #   value = c(70)
    # ),
    NULL,
    NULL #
  )
)

# myStyles <- c(list(color = "#3F517D")) # custom styles defined
# myNames <- list(c("gravitational")) # names to style
# myLevels <- list(2) # hierarchical levels to style

# plot sunburst
df |>
  e_charts(renderer = "svg") |>
  e_sunburst() |>
  e_labels(fontSize = 20)
  #e_sunburst(myStyles, myNames, myLevels)

```
:::

::: {.column width="50%"}
::: {.fragment .fade-in-then-semi-out .highlight-solubility}
```{=tex}
\begin{gather*}
pCO_{2}^{water~parcel} = \frac{[CO_{2}]}{K_{0}} \\
K_{0} \approx f(T)
\end{gather*}
```
:::

::: {.fragment .fade-in-then-semi-out .highlight-carbonate}
```{=tex}
\begin{gather*}
Ca^{2+} + 2HCO_{3}^{-} \rightleftharpoons CaCO_{3} + CO_{2} + H_{2}O
\end{gather*}
```
:::

::: {.fragment .highlight-bcp}
```{=tex}
\begin{gather*}
CO_{2} + H_{2}O \rightarrow CH_{2}O + O_{2}
\end{gather*}
```
:::
:::
:::

## Biological carbon pump (BCP)

<!-- ::: columns  -->

<!-- ::: {.column width="60%"} -->

<!-- ![](images/carbon_pumps_iversen2022.jpeg) <!-- ![](carbon_pumps_iversen2022.jpeg){.absolute top="60" left="-80" width="800" height="600"} -->

<!-- ::: -->

<!-- ::: {.column width="40%"} -->

<!-- ::: {.fragment .fade-in-then-semi-out} -->

<!-- ::: {style="position:absolute;top:30%;"} -->

<!-- {{< fa brands grav >}} Gravitational pump -->

<!-- ::: -->

<!-- ::: -->

<!-- ::: {.fragment .fade-in-then-semi-out} -->

<!-- ::: {style="position:absolute;top:40%;"} -->

<!-- {{< fa solid syringe >}} Vertical migration pump  -->

<!-- ::: -->

<!-- ```{=html} -->

<!-- <!-- <ul style= "list-style-type:square"> -->

<!-- <li>daily</li> -->

<!-- <li>seasonal</li> -->

<!-- </ul> -->

<!-- ``` -->

<!-- ::: -->

<!-- ::: {.fragment .fade-in-then-out} -->

<!-- ::: {style="position:absolute;top:50%;"} -->

<!-- {{< fa solid syringe >}} Mixing pump  -->

<!-- ::: -->

<!-- ```{=html} -->

<!-- <!-- <ul style= "list-style-type:square"> -->

<!-- <li>mixed layer</li> -->

<!-- <li>eddy subduction</li> -->

<!-- <li>large-scale subduction</li> -->

<!-- </ul> -->

<!-- ``` -->

<!-- ::: -->

<!-- ::: -->

<!-- ::: -->

![](images/refine/sysnthesis.svg)

## {{< fa brands grav >}} Gravitational pump (BGP) {.smaller}

::: {.panel-tabset}

### Spring bloom

```{r, tets}

# tiger <- image_read_svg('images/refine/gravitational_step2.svg', height = 600, width = 1000)
# tiger

```

![](images/refine/gravitational_step2.svg){.absolute width="850" height="800}

::: {style="position:absolute;top:25%;left:72%;"}
Winter --- Low phyto growth<br><br>
Spring --- Stratification <br><br>
Bloom --- BGP trigger <br><br>
Zoo graze and develop <br><br>
Fecal pellets + aggregates <br>
:::

### Twilight zone (TZ)

![](images/refine/gravitational_step3.svg){.absolute width="850" height="800}

::: {style="position:absolute;top:25%;left:72%;"}
BGP strength regulation<br><br>
Animal feeding<br>
Microbial degradation<br>
Fragmentation<br>
... <br>
{{< fa circle-exclamation >}} Sinking speed<br><br>
BGP \~ 70% export flux
:::


:::

## {{< fa solid syringe >}} Vertical migration pump (VMP) {.smaller}

::: {.panel-tabset}

### Diel

![](images/refine/diel.svg){.absolute width="850" height="800}

::: {style="position:absolute;top:35%;left:72%;"}
Night --- Surface feeding<br><br>
Day --- Avoid predation<br><br>
POC injection below EZ<br><br>
:::

### Seasonal (lipid pump) 

![](images/refine/seasonal.svg){.absolute width="850" height="800}

::: {style="position:absolute;top:35%;left:72%;"}
Summer --- carbon-rich lipids<br><br>
Winter --- Diapause<br><br>
Shunt carbon below pycnocline
:::


:::

## {{< fa solid syringe >}} Mixing pump {.smaller}

::: {.panel-tabset}

### Mixed layer

![](images/refine/mixed_layer.svg){.absolute width="850" height="800}

::: {style="position:absolute;top:35%;left:72%;"}
POC and DOC<br><br>
1D mechanism<br><br>
MLD transitions<br><br>
Mid and high latitudes<br><br>
:::

### Eddy-subduction

![](images/refine/eddy-subduction.svg){.absolute width="850" height="800}

::: {style="position:absolute;top:35%;left:72%;"}
2D mechanism<br><br>
Fronts and eddies<br><br>
Strong vertical circulation<br><br>
days ~ 1-10 km
:::

### Large-scale subduction

2D mechanism<br><br>
Meridional overturning and Ekman<br><br>
Slow advection<br><br>
~100-1000 km

:::

## Export range and sequestration time

::: {style="position:absolute;top:20%;"}
```{r table sequestration and export, cache=T}
df <- tibble(pump = c('Gravitational', 'Diel', 'Seasonal', 'Mixed layer', 'Eddy subduction', 'Large-scale subduction'),
             poc_injection = c('export depth - sediment', '200 - 600', '600 - 1400', '200 - 1000', '150 - 400', '200 - 1000'),
             doc_injection = c('N/A', 'N/A', 'N/A', '200 - 1000', '150 - 400', '200 - 1000'),
             sequestration_time = c('?', 'up to 250', 'up to 500', '25 - 100', 'up to 150', '25 - 100'),
             sequestration_time_bis = c('142', '150', '?', '54', '?', '54'))

kbl(df, col.names = c('Pump', 'POC', 'DOC', 'Boyd et al. (2019)', 'Nowicki et al. (2022)')) |>
  pack_rows("Vertical migration pump", 2,3, label_row_css = "background-color: #666; color: #fff;") |>
  pack_rows("Mixing pump", 4,6, label_row_css = "background-color: #666; color: #fff;") |>
  kable_styling(full_width = F, font_size = 21) |>
  add_header_above(c(" " = 1, "Export/injection depth range (m)" = 2, "Sequestration time (years)" = 2)) #|>
  #footnote(general = "N/A, not applicable", footnote_as_chunk = T)

# 
# # # Create a color vector with three colors
# colors <- c('#eb8146','#ffb248','#f2d643')
# 
# df <- tibble(Pump = c('Gravitational', 'Vertical migration', 'Mixing'),
#              group = rep('group'),
#              start = c(0,0,0),
#              end = c(70,10,20),
#              colors = colors)
# 
# # Create a stacked bar plot
# ggplot(df, aes(x = group, y = end, fill = Pump)) +
#   geom_bar(stat = "identity", position = "stack") +
#   coord_flip() + theme_void() + scale_y_reverse() +
#   theme(legend.position = "none") +
#   scale_fill_manual(values = colors) 

```
:::

::: {style="position:absolute;top:80%;"}
::: {.fragment .fade-in-then-out}
Export flux contribution: BGP (70%) - VMP (10%) - Mixing (20%)
:::
:::

::: {style="position:absolute;top:80%;"}
::: {.fragment .fade-in-then-out .highlight-bcp}
Large uncertainties remain
:::
:::

## Questions raised so far

::: {style="position:absolute;top:15%;"}
::: {.fragment .fade-in-then-semi-out}
{{< fa question-circle >}} How much carbon is exported/injected by each pump?<br>
{{< fa question-circle >}} How deep is it exported/injected?<br>
{{< fa question-circle >}} How long is it sequestered from the atmosphere?<br>
:::

::: {.fragment .fade-in-then-semi-out}
{{< fa lightbulb >}} Observational framework (Claustre et al., 2021)<br>
:::

::: {.fragment .fade-in-then-out}
{{< fa ship >}} Research vessels<br>
{{< fa satellite >}} Satellites<br>
{{< fa anchor >}} Instrumented moorings<br> 
{{< fa robot >}} Floats, gliders, USVs
:::
:::

::: {style="position:absolute;top:50%;"}
::: {.fragment .fade-in-then-out .highlight-bcp}
{{< fa robot >}} Floats
:::
:::

## Biogeochemical-Argo float (BGC-Argo)

::: columns
::: {.column width="40%"}
::: resize
![](images/float_picture1.png)
:::
:::

::: {.column width="60%"}
![](images/argo_float_profiling.jpeg){.absolute top="150" width="700" height="525"}
:::
:::

# UVP6 embedded classification {background-color="black"}

## Underwater Vision Profiler 6 (UVP6)

::: {style="position:absolute;top:15%;"}
::: columns
::: {.column width="50%"}
![](images/UVP6_b.png)
:::

::: {.column width="50%"}
0.7L imaged volume <br><br> Particle counter (0.1 - 2.5 mm)<br> Particle classifier (\> 0.6 mm)<br><br> Particle size distribution (PSD)<br> Carbon flux estimations<br> Organism studies (e.g VMP)<br>
:::
:::
:::

::: {style="position:absolute;top:75%;left:60%"}
```{r, mozaic}

read_image <- function(path_to_image){
  image <- image_scale(image_read(path_to_image), "150x150")
  return(image)
}

image_folder <- '/home/flo/dox/PhD_PRESENTATION/images/uvp6_images/alive_inverted/'
all_files <- list.files(image_folder, full.names = T)
list_image <- map(all_files, read_image)

all_images <- c(list_image[[1]], list_image[[2]], list_image[[3]], list_image[[4]], list_image[[5]], 
                list_image[[2]], list_image[[3]], list_image[[4]], list_image[[5]], list_image[[6]], 
                list_image[[7]], list_image[[8]], list_image[[9]], list_image[[10]], list_image[[11]], 
                list_image[[12]], list_image[[13]], list_image[[14]], list_image[[15]], list_image[[16]], 
                list_image[[17]], list_image[[18]], list_image[[19]], list_image[[20]])

image_animate(all_images, fps = 1, dispose = "previous")

```
:::

<!-- ## {background-image="images/uvp6_images/mosaic_big.png"} -->

<!-- ::: footer -->
<!-- Not at scale -->
<!-- ::: -->

## Why <ins>embedded</ins> classification?

::: {style="position:absolute;top:15%;"}

::: {.fragment .fade-in-then-semi-out}

{{< fa clock >}} Transmission time<br>

::: small-text
Iridium cost<br>
Biofouling and other hazards<br>
Power consumption (float battery life)<br><br>
:::

:::

::: {.fragment .fade-in-then-semi-out}

::: columns
::: {.column width="55%"}
{{< fa question-circle >}} Which classification model?<br>

::: small-text
Convolutional neural network (CNN)<br>
~State-of-the-art but energy consuming
:::

:::
::: {.column width="45%"}
![](images/uvp6_images/cnn.png)
:::
:::
:::

::: {style="position:absolute;top:80%;"}
::: {.fragment .fade-in-then-semi-out}
{{< fa lightbulb >}} Extreme gradient boosting<br>

::: small-text
Efficient and portable <span style="color: gray;">(Chen et al., 2016)</span>
:::

:::
:::

:::

## A features-based classifier called XGBoost

::: columns
::: {.column width="50%"}
![](images/uvp6_images/xgboost_full.svg){width="666" height="500"}

::: footer
Figure from Geron et al. (2019)
:::

:::
::: {.column width="50%"}
{{< fa hands-bound >}} With constraints<br>

::: small-text
55 (handcrafted) features<br>
40 labels max<br>
Model size (loading time < 700 ms)<br><br>
:::

:::
:::

## Training set of extracted features {.smaller}

::: columns
::: {.column width="60%"}
::: {style="position:absolute;left:0%;"}
```{r, table of features, cache=T}

tmp <- vroom::vroom('images/uvp6_images/features_test.csv') |> select(area, mean, eccentricity, angle, hu_moment_1 = `hu_moment-1`, labels, objid) |> mutate(image = "") |> select(image, labels, everything()) |> mutate(mean = floor(mean), eccentricity = round(eccentricity, 2), angle = round(angle, 2), hu_moment_1 = round(hu_moment_1,2))
tmp <- tmp |> filter(objid %in% c(294999773,287246779,287249133,287246708,287246365)) |> select(-objid) |> mutate(more = "...")
tmp <- as.data.frame(tmp)

tmp$image <- c("/home/flo/dox/PhD_PRESENTATION/images/uvp6_images/alive_inverted/294999773_inverted.png", 
               "/home/flo/dox/PhD_PRESENTATION/images/uvp6_images/alive_inverted/287246779_inverted.png",
               "/home/flo/dox/PhD_PRESENTATION/images/uvp6_images/alive_inverted/287249133_inverted.png", 
               "/home/flo/dox/PhD_PRESENTATION/images/uvp6_images/alive_inverted/287246708_inverted.png",
               "/home/flo/dox/PhD_PRESENTATION/images/uvp6_images/alive_inverted/287246365_inverted.png")

# tmp$area <- cell_spec(tmp$area, background = dplyr::if_else(tmp$area > 20000, "#FF9999", dplyr::if_else(tmp$area < 600, 'lightblue', '')))
# tmp$mean <- cell_spec(tmp$mean, background = dplyr::if_else(tmp$mean > 161, "#FF9999", dplyr::if_else(tmp$mean < 55, 'lightblue', '')))
# tmp$eccentricity <- cell_spec(tmp$eccentricity, background = dplyr::if_else(tmp$eccentricity > 0.98, "#FF9999", dplyr::if_else(tmp$eccentricity < 0.3, 'lightblue', '')))
# 
# 
# fig <- tmp |> kbl(format = 'html', digits = 2, col.names = c('', 'Label', '# pixels', 'Mean gray level', 'Eccentricity', '52/55'), escape = F) |> column_spec(1, image = spec_image(c("/images/uvp6_images/alive_inverted/294999773_inverted.png", "/images/uvp6_images/alive_inverted/287246779_inverted.png",
#                                                                     "/images/uvp6_images/alive_inverted/287249133_inverted.png", "/images/uvp6_images/alive_inverted/287246708_inverted.png",
#                                                                 "/images/uvp6_images/alive_inverted/287246365_inverted.png"), 300, 200)) |>
#   kable_paper("hover", full_width = F) |>
#   kable_styling(bootstrap_options = "striped", font_size = 20, row_label_position = 'c')
# 
# fig

tmp |>
   gt() |>
   gt_img_rows(columns = image, img_source = "local", height = 75) %>%
   tab_options(data_row.padding = px(1)) |>
   cols_label(image = md('**Image**'),
             labels = md('**Label**'),
             area = md('**Area**'),
             mean = md('**Mean**'),
             eccentricity = md('**Eccentricity**'),
             angle = md('**Orientation angle**'),
             hu_moment_1 = md('**Hu moment-1**'),
             more = md('**50/55**')) |>
  cols_align("center") |>
  tab_style_body(
    style = cell_fill(color = "#22a7f0"),
    values = c(53, 591, 0.28, -1.45, 0.26)
  ) |>
    tab_style_body(
    style = cell_fill(color = "#e14b31"),
    values = c(210812,162,0.99,1.17,0.81)
  ) 
```
:::
:::
::: {.column width="40%"}


::: {style="position:absolute;top:50%;"}
Training set (90%) --- test set<br>
<span>&#8594;</span> Start training
:::


:::
:::

## 600.000 UVP6 images over +100 labels {.smaller}

::: {.panel-tabset}

### From +100

```{r, map uvp6}

uvp6_labels <- vroom::vroom('images/uvp6_images/levels_uvp6.csv') |> mutate(category = 'living')
non_living <- c('artefact', 'detritus', 'crystal', 'fiber')
uvp6_labels[uvp6_labels$level2.5 %in% non_living,]$category <- 'non-living'
non_living <- c('artefact', 'detritus', 'crystal', 'fiber') # need to be used here again because the line before engedered a bug with highcharter
```

```{r, all labels}

#  Create a packed bubble chart
# highchart(width = 550, height = 400) |>
#   hc_chart(type = "packedbubble") |>
#   hc_add_series(uvp6_labels, "packedbubble", hcaes(name = level0, value = n0, group = category)) |>
#   hc_plotOptions(packedbubble = list(
#     tooltip = list(
#       pointFormat = "<b>{point.name}:</b> {point.value}<br>"
#     ),
#     maxSize = "500%",
#     minSize = "50%"))

# x <- c(rnorm(10000), rnorm(1000, 4, 0.5))
# 
# hchart(x, name = "data") 


# uvp6_labels_v2 <- uvp6_labels |> select(level2.5, n2.5, category) |> distinct()
# uvp6_labels_v2 <- uvp6_labels_v2[-c(12,20,23),]
# 
# uvp6_labels_v2$group2 <- c('Trichodesmium', 'Trichodesmium', 'Rhizaria', 'Rhizaria', 'other-living','Rhizaria', 'Rhizaria', 'Rhizaria', 'Rhizaria', 'Copepoda', 'non-living', 'Chaetognatha','Actinopterygii',
#                            'Appendicularia', 'Salpida', 'Cnidaria', 'Creseis', 'non-living', 'non-living', 'non-living')
# 
# # uvp6_labels_v2$group2 <- c('Trichodesmium', 'Trichodesmium', 'Rhizaria', 'Rhizaria', 'other-living','Rhizaria', 'Rhizaria', 'Rhizaria', 'Rhizaria', 'other-living', 'non-living', 'other-living','other-living',
# #                            'other-living', 'other-living', 'other-living', 'other-living', 'non-living', 'non-living', 'non-living')
# 
# # Create a packed bubble chart
# hc <- highchart(width = 550, height = 600) |>
#   hc_chart(type = "packedbubble") |>
#   hc_add_series(uvp6_labels_v2, "packedbubble", hcaes(name = level2.5, value = n2.5, group = group2)) |>
#   hc_plotOptions(packedbubble = list(
#     tooltip = list(
#       pointFormat = "<b>{point.name}:</b> {point.value}<br>"
#     ),
#     maxSize = "200%",
#     minSize = "30%",
#     zMin = 0,
#              layoutAlgorithm = list(
#                  gravitationalConstant =  0.05,
#                  splitSeries =  TRUE, # TRUE to group points
#                  seriesInteraction = TRUE,
#                  dragBetweenSeries = TRUE,
#                  parentNodeLimit = TRUE
#              )))
# 
# # Display the chart
# hc

# x <- c(rnorm(10000), rnorm(1000, 4, 0.5))
# 
# hchart(x, name = "data") 


highchart(width = 550, height = 400) |>
  hc_chart(type = "packedbubble") |>
  hc_add_series(uvp6_labels, "packedbubble", hcaes(name = level0, value = n0, group = category)) |>
  hc_plotOptions(packedbubble = list(
    tooltip = list(
      pointFormat = "<b>{point.name}:</b> {point.value}<br>"
    ),
    maxSize = "500%",
    minSize = "50%"))

```

::: {style="position:absolute;top:25%;left:50%;"}

{{< fa triangle-exclamation >}} 40 labels max<br><br>

90% non-living<br>
80% detritus<br><br>

2% Calanoida<br>
2% Trichodesmium<br>
6% smaller groups<br>

50 --- median class size

:::

```{r, some stats}

uvp6_labels <- uvp6_labels |> mutate(pc = 100*(n0/sum(n0)))

#uvp6_labels_v2 <- uvp6_labels_v2 |> mutate(pc = 100*(count/sum(count)))
```

### To 20

```{r, less labels}

# uvp6_labels_v2 <- uvp6_labels |> select(level2.5, n2.5, category) |> distinct()
# uvp6_labels_v2 <- uvp6_labels_v2[-c(19,20,23),]
uvp6_labels_v2 <- vroom::vroom('images/uvp6_images/uvp6_label_79px.csv')
uvp6_labels_v2 <- uvp6_labels_v2 |> group_by(labels) |> summarize(count = n()) |> mutate(category = 'living')
uvp6_labels_v2[uvp6_labels_v2$labels %in% non_living,]$category <- 'non-living'
uvp6_labels_v2[uvp6_labels_v2$labels == 'small<Cnidaria',]$labels <- 'small-Cnidaria'
uvp6_labels_v2[uvp6_labels_v2$labels == 'other<living',]$labels <- 'other-living'

# uvp6_labels_v2$group2 <- c('Trichodesmium', 'Trichodesmium', 'Rhizaria', 'Rhizaria', 'other-living','Rhizaria', 'Rhizaria', 'Rhizaria', 'Rhizaria', 'Copepoda', 'non-living', 'Chaetognatha','Actinopterygii',
#                            'Appendicularia', 'Salpida', 'Cnidaria', 'Creseis', 'non-living', 'non-living', 'non-living')

# uvp6_labels_v2$group2 <- c('Trichodesmium', 'Trichodesmium', 'Rhizaria', 'Rhizaria', 'other-living','Rhizaria', 'Rhizaria', 'Rhizaria', 'Rhizaria', 'other biological groups', 'non-living', 'other biological groups','other biological groups',
#                            'other biological groups', 'other biological groups', 'other biological groups', 'other biological groups', 'non-living', 'non-living', 'non-living')

uvp6_labels_v2$group2 <- c('Rhizaria', 'other biological groups', 'other biological groups', 'Rhizaria', 'other biological groups','other biological groups', 'Rhizaria', 'other biological groups', 'Rhizaria', 'Rhizaria', 'other biological groups', 'non-living','non-living','non-living', 'non-living', 'other-living', 'Trichodesmium', 'other biological groups', 'Rhizaria', 'Trichodesmium')


# Create a packed bubble chart
hc <- highchart(width = 550, height = 400) |>
  hc_chart(type = "packedbubble") |>
  hc_add_series(uvp6_labels_v2, "packedbubble", hcaes(name = labels, value = count, group = group2)) |>
  hc_plotOptions(packedbubble = list(
    tooltip = list(
      pointFormat = "<b>{point.name}:</b> {point.value}<br>"
    ),
    maxSize = "100%",
    minSize = "10%",
    zMin = 0,
             layoutAlgorithm = list(
                 gravitationalConstant =  0.05,
                 splitSeries =  TRUE, # TRUE to group points
                 seriesInteraction = TRUE,
                 dragBetweenSeries = TRUE,
                 parentNodeLimit = TRUE
             )))

# Display the chart
hc

# highchart(width = 550, height = 400) |>
#   hc_chart(type = "packedbubble") |>
#   hc_add_series(uvp6_labels, "packedbubble", hcaes(name = level0, value = n0, group = category)) |>
#   hc_plotOptions(packedbubble = list(
#     tooltip = list(
#       pointFormat = "<b>{point.name}:</b> {point.value}<br>"
#     ),
#     maxSize = "500%",
#     minSize = "50%"))

```
::: {style="position:absolute;top:25%;left:50%;"}

90% non-living<br>
80% detritus<br><br>


2% Trichodesmium<br>
1% Rhizaria group<br>
4.5% specific biological groups (2.5% Calanoida)<br>
2.5% non-specific (other-living)<br><br> 

1000 --- median class size

:::

### By using metrics and phylogeny

```{r, confusion matrix and phylogeny}
 
gray_levels_uvp6 <- array(t(npyLoad('/home/flo/dox/THESIS/DATA/UVP6/cm_uvp6.npy')))

x <- c('Acantharia', 'Actinopterygii', 'Appendicularia', 'Aulacanthidae',
       'Calanoida', 'Chaetognatha', 'Collodaria', 'Creseis',
       'Foraminifera', 'Rhizaria', 'Salpida', 'artefact', 'crystal',
       'detritus', 'fiber', 'other<living', 'puff', 'small<Cnidaria',
       'solitaryglobule', 'tuff')

# x <- factor(x, levels = x)
# y <- factor(y, levels = rev(y))
data <- expand.grid(X=x, Y=x, stringsAsFactors = T)
data$gray_levels <- gray_levels_uvp6 * 100

w <- rnorm(10) # need to add a stupid variable not related to a highcharter or echarts4r to avoid issue with JS..

data |> e_charts(X, renderer = "svg") |>
  e_heatmap(Y,gray_levels) |>
  e_visual_map(gray_levels) |>
  e_x_axis(axisLabel = list(rotate = 45)) |>
  e_grid(height = "70%", width = "50%", left = "15%") |>
  e_x_axis(
    name = "Predicted labels",
    offset = 0,
    nameGap = 60,
    nameLocation = "center",
    nameTextStyle = list(
      color = "black",
      fontWeight = "bold"
    )
  ) |>
    e_y_axis(
    name = "True labels",
    offset = 0,
    nameGap = 90,
    nameLocation = "center",
    nameTextStyle = list(
      color = "black",
      fontWeight = "bold"
    )
  )

w <- rnorm(10)

```

::: {style="position:absolute;top:25%;left:65%;"}

<!-- $$Recall = \frac{\mathrm{\#~true~positive~predictions}}{\mathrm{\#~all~actual~positive~instances}}$$ -->
<!-- $$Precision = \frac{\mathrm{\#~true~positive~predictions}}{\mathrm{\#~all~positive~predictions}}$$ -->
$$Recall = \frac{TP}{TP+FN}$$
$$Precision = \frac{TP}{TP+FP}$$
<br>Merging classes based on<br>
<span style="font-size: 24px;">scarcity --- confusion<br></span>
<span style="font-size: 24px;">morphology --- ecology<br></span>
:::

:::

```{r}
w <- rnorm(10)
```



## 80% of detritus for 10% of biological groups {.smaller}

```{r, detritus curse}

w <- rnorm(10)

x <- c('Acantharia', 'Aulacanthidae', 'Aulosphaeridae', 'Copepoda', 'Trichodesmium', 
            'artefact', 'bubble', 'darksphere', 'detritus_0', 'detritus_1', 'detritus_2', 'detritus_3', 'detritus_4', 'fiber', 'other<living')

y <- factor(x, levels = rev(x))

data <- expand.grid(X=x, Y=y, stringsAsFactors = T)

gray_levels_ndetritus <- c(64,252,249,255,250,255,255,255,255,240,253,247,254,249,251,
                           253,55,247,255,247,246,255,255,250,253,255,252,251,255,249,
                           254,252,0,255,255,255,255,255,250,250,255,250,254,255,250,
                           255,255,255,137,254,254,255,255,247,231,253,229,230,255,251,
                           254,255,255,255,33,255,255,253,254,251,255,238,246,249,255,
                           255,255,255,255,255,51,255,255,252,245,253,219,255,255,255,
                           255,255,255,255,253,250,11,255,253,251,255,247,245,255,255,
                           254,252,253,255,250,254,254,76,253,254,255,252,214,255,251,
                           255,255,255,255,255,181,255,255,253,192,247,239,255,226,251,
                           255,255,255,255,254,193,255,255,248,189,249,212,255,246,251,
                           255,255,255,254,255,212,255,255,253,194,221,242,255,229,251,
                           255,255,255,255,255,181,255,255,250,161,251,229,255,247,252,
                           255,255,255,253,253,249,255,255,246,239,255,173,159,252,255,
                           255,255,255,254,250,253,255,255,253,229,249,213,243,138,255,
                           251,252,253,246,252,242,254,253,247,246,253,247,249,245,134)

gray_levels_ndetritus <- 100*(abs(gray_levels_ndetritus - 255)/255)

data$gray_xgboost_ndetritus <- gray_levels_ndetritus

data |> e_charts(X, renderer = "svg") |>
  e_heatmap(Y,gray_xgboost_ndetritus) |>
  e_visual_map(gray_xgboost_ndetritus) |>
  e_x_axis(axisLabel = list(rotate = 45)) |>
  e_grid(height = "70%", width = "45%", left = "15%") |>
  e_x_axis(
    name = "Predicted labels",
    offset = 0,
    nameGap = 60,
    nameLocation = "center",
    #axisLabel = list(fontSize=c(seq(1,15,1))),
    nameTextStyle = list(
      color = "black",
      fontWeight = "bold"
    )
  ) |>
    e_y_axis(
    name = "True labels",
    offset = 0,
    nameGap = 90,
    nameLocation = "center",
    nameTextStyle = list(
      color = "black",
      fontWeight = "bold"
    )
  )  |>
  e_mark_line(data = list(xAxis = 'detritus_0'), title = "N = 0") |>
  e_mark_line(data = list(xAxis = 'detritus_4'), title = "N = 4")

w <- rnorm(10)

```

::: {style="position:absolute;top:15%;left:62%;"}

{{< fa bullseye >}} Improving biological score<br><br>
Detritus<br>
<span style="font-size: 20px;">Variety of shapes --- sizes --- gray levels<br></span>
<span style="font-size: 20px;">Clustering them?</span><br><br>
N detritus classes<br>
<span style="font-size: 20px;">Continuum in the features space</span><br>
<span style="font-size: 20px;">Inter-group confusion</span><br>
<span style="font-size: 20px;">Does not improve biological score</span><br><br>
{{< fa lightbulb >}} Add weights on biological classes
:::

## CNN is better but not energy limited {.smaller}

::: {style="position:absolute;top:15%;left:0%;"}
```{r, UVP6 vs CNN}

labels <- c('Acantharia', 'Actinopterygii', 'Appendicularia', 'Aulacanthidae', 'Calanoida', 'Chaetognatha', 'Collodaria', 'Creseis', 'Foraminifera', 'Rhizaria', 'Salpida', 'artefact', 'crystal', 'detritus', 'fiber','other<living', 'puff', 'small<Cnidaria', 'solitaryglobule', 'tuff', 'accuracy','macro avg', 'weighted avg', 'living macro avg', 'living weighted avg')

precision <- c(0.89,1,0.89,0.82,0.66,0.80,.73,0.81,0.71,0.69,0.63,0.91,0.89,0.95,0.73,0.44,0.73,0.55,0.83,0.55,0.91,0.76,0.91,0.73,0.61)*100
recall <- c(0.69,0.40,0.44,0.89,0.69,0.62,0.62,1,0.48,0.75,0.61,0.92,0.89,0.95,0.83,0.24,0.78,0.47,0.71,0.63,0.91,0.68,0.91,0.63,0.56)*100

precision_cnn <- c(0.98,0.47,0.38,0.86,0.82,0.52,0.74,0.42,0.76,0.71,0.74,0.94,0.69,0.98,0.77,0.55,0.84,0.72,0.81,0.68,0.94,0.72,0.94,0.69,0.71)*100
recall_cnn <- c(1,0.73,0.64,0.86,0.89,0.88,0.88,1,0.89,0.92,0.89,0.92,0.97,0.96,0.85,0.62,0.94,0.86,0.88,0.93,0.94,0.88,0.94,0.86,0.82)*100

category <- c(rep('living',11), rep('non-living',4), rep('living', 5), rep('summary', 5))

uvp6_labels_v3 <- uvp6_labels_v2 |> mutate(nb_test_set = floor(count*0.1)) #|> rbind(tibble(labels = '...', count = '...', category = '...', group2 = '...', nb_test_set = '...'))

cf_uvp6_xgboost_cnn <- tibble(labels, precision, recall, precision_cnn, recall_cnn, category) |> mutate(nb = c(uvp6_labels_v3$nb_test_set, rep('', 5)))

# insert dotted info

#colnames(cf_uvp6_xgboost_cnn) <- c('Labels', 'Precision', 'Recall', 'Precision', 'Recall')

cf_uvp6_xgboost_cnn |>
  mutate(diff_cnn_prec = precision_cnn - precision, diff_cnn_recall = recall_cnn - recall) |>
  select(labels, precision, diff_cnn_prec, recall, diff_cnn_recall, category) |>
  filter(labels %in% c('detritus', 'fiber', 'other<living', 'Calanaoida', 'puff', 'tuff', 'Chaetognatha', 'Foraminifera', 'accuracy', 'macro avg', 'living macro avg', 'living weighted avg')) |>
  gt() |>
  tab_row_group(label = "Summary", category == "summary") |>
  tab_row_group(label = "Non-living (2/4)", category == "non-living") |>
  tab_row_group(label = "Biological groups (5/16)", category == "living") |>
  gt_plt_bar(column = diff_cnn_prec, keep_column = F, width = 35, scale_type = "number", color = '#DC3B34FF') |>
  gt_plt_bar(column = diff_cnn_recall, keep_column = F, width = 35, scale_type = "number", color = '#001852') |>
  # gt_add_divider(columns = "recall", sides = "left") |>
  # gt_add_divider(columns = labels, sides = 'right') 
  #gt_color_rows(precision, palette = "viridis")
  gt_color_rows(precision) |>
  gt_color_rows(recall, palette = "ggsci::blue_material") |>
  tab_options(row_group.font.weight = "bold") |>
  cols_hide(columns = 'category') |>
  tab_spanner(label = 'Precision', columns = c('precision', 'diff_cnn_prec')) |>
  tab_spanner(label = 'Recall', columns = c('recall', 'diff_cnn_recall')) |>
  cols_label(labels = '', precision = 'XGBoost', diff_cnn_prec = "CNN difference", recall = "XGBoost", diff_cnn_recall = "CNN difference")

```
:::

## {{< fa check >}} Take-home message #1

# UVP6 and OST in the Labrador Sea {background-color="black"}

2 independent measurements of particle and carbon fluxes

## {{< fa bell >}} Transition slide

bosser les transitions avec teintes de gris par rapport aux questions et faire une slide de rapport pour montrer le fil

## Optical Sediment Trap (OST)

::: {style="position:absolute;top:15%;"}
::: columns
::: {.column width="50%"}
![](labrador/low_quality_ost.jpg)
:::

::: {.column width="50%"}
Vertical transmissometer <br><br> 

::: {style="position:absolute;top:40%;"}
Particle accumulation<br> 
:::

::: {style="position:absolute;top:5%;"}
```{=tex}
\begin{gather*}
\small{c_{p} \approx -\frac{ln(T_{r})}{L}, ATN = c_{p} \times L}
\end{gather*}
```
:::

::: {style="position:absolute;top:50%;"}
::: small-text 
Small (continuous accumulation) <br> 
Large (discontinuous - jumps) <br><br>
:::

Downward POC flux (BGP)
F<sub>small</sub> & F<sub>large</sub> POC fluxes

:::
:::
:::
:::

## OST used during float drifting

```{r, floats + drifting}

float_6904240 <- vroom('/home/flo/dox/ArgoShine/6904240_FromNetCDF.csv')
float_6904241 <- vroom('/home/flo/dox/ArgoShine/6904241_FromNetCDF.csv')
float_4903634 <- vroom('/home/flo/dox/ArgoShine/4903634_FromNetCDF.csv')
float_1902578 <- vroom('/home/flo/dox/ArgoShine/1902578_FromNetCDF.csv')

# combine all data
all_floats <- rbind(float_6904240, float_6904241, float_4903634, float_1902578)

# add levels for some field
all_floats <- all_floats |> dplyr::mutate(wmo = factor(wmo, levels = c(6904240,4903634,6904241,1902578)), park_depth = factor(park_depth, levels = c('200 m', '500 m', '1000 m')))

plot_jumps <- function(data){
  
  # make sure that the cp signal is in chronological order
  tmp <- data |> arrange(dates)
  
  # despike cp data with a 7-point moving window
  tmp$cp <- despike(tmp$cp, k = 3)
  
  # smooth cp data with a 7-point moving median, n time(s)
  tmp$cp <- slide(tmp$cp, fun = median, k = 3, n = 1, na.rm=T)
  
  # compute slope between two adjacent points (except first point) # we could start after 1h to let the float stabilize
  delta_x <- as.numeric(tmp$dates - lag(tmp$dates), units = 'days')
  delta_y <- tmp$cp - lag(tmp$cp)
  tmp$slope <- delta_y/delta_x
  
  # compute a Z score (assuming a normal distribution of the slopes) on the slopes
  tmp <- tmp |> mutate(zscore = (slope - mean(slope, na.rm = T))/sd(slope, na.rm = T))
  
  # spot outliers on the Z score signal
  # interquartile range between Q25 and Q75
  # IQR <- quantile(tmp$zscore, probs = 0.75, na.rm=T) - quantile(tmp$zscore, probs = 0.25, na.rm=T)
  # # outliers ('spikes' in the Z score signal)
  # spikes_down <- tmp$zscore < quantile(tmp$zscore, 0.25, na.rm=T) - 1.5 *IQR
  # spikes_up <-  tmp$zscore > quantile(tmp$zscore, 0.75, na.rm=T) + 1.5 *IQR
  # spikes <- as.logical(spikes_down + spikes_up)
  
  IQR <- quantile(tmp$slope, probs = 0.75, na.rm=T) - quantile(tmp$slope, probs = 0.25, na.rm=T)
  # outliers
  spikes_down <- tmp$slope < quantile(tmp$slope, 0.25, na.rm=T) - 1.5 *IQR
  spikes_up <-  tmp$slope > quantile(tmp$slope, 0.75, na.rm=T) + 1.5 *IQR
  spikes <- as.logical(spikes_down + spikes_up)
  
  # assign spikes
  tmp$spikes <- spikes
  
  # assign colour code to cp signal
  tmp$colour <- 'base signal' # base signal = smoothed despiked cp signal
  tmp[which(tmp$spikes == TRUE),]$colour <- 'jump'
  
  # add group to compute the slope of each group of points, separated by a jump
  tmp$group <- NA
  
  # index of jumps in the array
  jump_index <- which(tmp$colour == 'jump')
  
  # assign group identity to each group of points, separated by a jump (= subgroup)
  for (i in jump_index){
    for (j in 1:nrow(tmp)){
      if ((j < i) & (is.na(tmp$group[j]))){
        tmp$group[j] <- paste0('group_',i)
      }
    }
  }
  tmp$group[which(is.na(tmp$group))] <- 'last_group'
  
  # compute slope for each subgroup
  slope_df <- tmp |> filter(colour == 'base signal', slope != 'NA') |> dplyr::group_by(group) |> dplyr::summarise(min_time = min(dates), max_time = max(dates), 
                                                                                                                  nb_points = n(), first_cp = cp[1], last_cp = cp[nb_points],
                                                                                                                  delta_x = as.numeric(difftime(max_time, min_time, units = 'days')),
                                                                                                                  delta_y = (last_cp-first_cp)*0.25, slope = delta_y/delta_x) # *0.25 to convert cp to ATN
  
  # remove negative slope from the mean slope (no physical meaning)
  slope_df <- slope_df |> filter(slope > 0)
  
  # remove if only one point (cannot fit a slope with one point)
  slope_df <- slope_df |> filter(nb_points > 3)
  
  # compute weighted average slope (to take into account the fact that some subgroup might have 2 points and a high slope vs. large group of points with a small slope)
  mean_slope <- sum(slope_df$nb_points * slope_df$slope)/sum(slope_df$nb_points)
  
  # convert cp to POC using Estapa's relationship 
  poc_flux <- 633*((mean_slope)**0.77) # /!\ slope computed for ATN on y axis (delta_y *0.25 because ATN = cp*0.25) -> should be OK
  
  # build dataframe to plot each subgroup
  part1 <- slope_df |> select(group, time = min_time, cp = first_cp)
  part2 <- slope_df |> select(group, time = max_time, cp = last_cp)
  part_slope <- rbind(part1, part2)
  
  # spot negative jump
  tmp$colour[which((tmp$colour == 'jump') & (tmp$slope < 0))]  <- 'negative jump'
  
  # add big particles flux to the party
  rows_to_keep <- c(jump_index, jump_index-1)
  tmp2 <- tmp[rows_to_keep,] |> select(dates, cp, slope, colour, group) |> arrange(dates)
  
  # remove negative jump, if any
  check_colour <- unique(tmp2$colour)
  # if(length(check_colour) == 3){ # there is a negative jump
  #   index_neg_jump <- which(tmp2$colour == 'negative jump')
  #   tmp2 <- tmp2[-c(index_neg_jump, index_neg_jump+1),]
  #   tmp2 <- tmp2 |> mutate(diff_jump = cp - lag(cp)) 
  #   even_indexes <- seq(2,nrow(tmp2),2)
  #   tmp2 <- tmp2[even_indexes,]
  # }else if(length(check_colour) == 2){ # only positive jump
  #   tmp2 <- tmp2 |> mutate(diff_jump = cp - lag(cp)) 
  #   even_indexes <- seq(2,nrow(tmp2),2)
  #   tmp2 <- tmp2[even_indexes,]
  # }else{ # No jump
  #   tmp2 <- NULL
  # }
  if(length(check_colour) >= 2){ # there is a least a jump (positive or negative)
    tmp2 <- tmp2 |> mutate(diff_jump = cp - lag(cp)) 
    even_indexes <- seq(2,nrow(tmp2),2)
    tmp2 <- tmp2[even_indexes,]
  }else{ # No jump
    tmp2 <- NULL
  }
  
  if(is.null(tmp2)){ # no jumps
    big_part_poc_flux <- 0
    tmp3 <- NULL
  }else{
    tmp3 <- tmp2 |> filter(diff_jump > 0)
    if(nrow(tmp3) == 0){ # no positive jumps
      big_part_poc_flux <- 0
    }else{
      delta_y <- sum(tmp3$diff_jump) *0.25 # to get ATN (= cp*0.25)
      max_time <- max(tmp$dates)
      min_time <- min(tmp$dates)
      delta_x <- as.numeric(difftime(max_time, min_time, units = 'days'))
      slope_big_part <- delta_y/delta_x
      big_part_poc_flux <- 633*(slope_big_part**0.77)
    }
  }
  
  # compute total drifting time
  max_time <- max(tmp$dates)
  min_time <- min(tmp$dates)
  drifting_time <- as.numeric(difftime(max_time, min_time, units = 'days'))
  
  # to plot subgroups
  part_slope_tmp <- part_slope |> mutate(dates = time, colour = 'slope')
  
  jump_plot <- plot_ly(tmp, x = ~dates, y = ~cp, type = 'scatter', mode = 'markers', color = ~colour, colors = c('#003366','#E31B23', '#FFC325')) |>
    add_lines(data= part_slope_tmp, x = ~dates, y = ~cp, split = ~group, color = I('#DCEEF3'), showlegend = F) |>
    layout(title= list(text = paste0('Drifting time: ', round(drifting_time,1), ' days\n',
                         'ATN slope: ', round(mean_slope,3), ' day<sup>-1</sup>\n',
                         'F<sub>small</sub>: ', round(poc_flux,1), ' mg C m<sup>-2</sup> day<sup>-1</sup>\n',
                         'F<sub>large</sub>: ', round(big_part_poc_flux,1), ' mg C m<sup>-2</sup> day<sup>-1</sup>'), x = 0.1, y = 0.9), yaxis = list(title = 'C<sub>p</sub> (m<sup>-1</sup>)'), xaxis = list(title = 'Time')) |>
    config(displayModeBar = FALSE)
  
  
  #return(jump_plot)
  return(list('jump_plot' = jump_plot, 'jump_table' = tmp3))
}

ost_df <- float_6904240 |> filter(PhaseName == 'PAR', cycle == 21, park_depth == '1000 m') |> drop_na(cp) |>
      select(depth = pres, cp, dates = juld, park_depth)

output <- plot_jumps(ost_df)
output$jump_plot

```

::: small-text
F<sub>small</sub> = 633 x (ATN<sub>slope</sub>)<sup>0.77</sup> <span style="color: gray;">(Estapa et al., 2023)</span> <br> F<sub>large</sub> = 633 x (Jump<sub>total</sub>/drifting time)<sup>0.77</sup>
:::

## 4 BGC-Argo floats deployed in May 2022

::: footer
Last updated on `r format(Sys.time(), '%d %B, %Y', tz = 'UTC')`
:::

::: {style="position:absolute;top:20%;left:-15%;"}
```{r, study site Labrador}

# summarize localization of floats
argo_map <- all_floats |> select(WMO = wmo, cycle, lat, lon) |> drop_na(lat) |> dplyr::group_by(WMO, cycle) |> dplyr::mutate(WMO = factor(WMO)) |>
  dplyr::summarise(lat = mean(lat), lon = mean(lon))

argo_map_first <- argo_map |> filter(cycle == 1)
argo_map_last <- argo_map |> filter(cycle == max(cycle))

# prepare data for geomapping, see https://mikkovihtakari.github.io/ggOceanMaps/
argo_map_geo <- transform_coord(argo_map) |> dplyr::mutate(cycle = argo_map$cycle, WMO = as.factor(argo_map$WMO))
argo_map_last_geo <- transform_coord(argo_map_last) |> mutate(WMO = as.factor(argo_map_last$WMO))

p <- basemap(limits = c(-55,-40,55,65), bathymetry = T, lat.interval = 2.5, bathy.style = 'poly_blues', bathy.alpha = .5) 

# Make the graticules:
lims <- attributes(p)$limits 
graticule <- sf::st_graticule(
  c(lims[1], lims[3], lims[2], lims[4]), 
  crs = attributes(p)$proj,
  lon = attributes(p)$map.grid$lon.breaks, 
  lat = attributes(p)$map.grid$lat.breaks
)

p <- p + 
  geom_sf(data = graticule, color = "grey", size = LS(1)) + # graticules
  coord_sf(xlim = lims[1:2], ylim = lims[3:4], # redefine limits
           crs = attributes(p)$proj) 

p +
  geom_path(data = argo_map_geo, aes(lon, lat, colour = WMO), linewidth = 1) + 
  geom_point(data = argo_map_geo, aes(x= lon, y = lat, colour = WMO), size = 2) +
  #scale_color_brewer(palette = 'Dark2') + 
  scale_colour_manual(values = c('#D95F02', '#7570B3', '#E6AB02', '#1B9E77')) +
  theme_bw() +
  geom_point(data = transform_coord(argo_map_first), aes(lon, lat), shape = 17, size = 3) +
  geom_point(data = argo_map_last_geo, aes(lon, lat, colour = WMO), size = 4) +
  geom_point(data = argo_map_last_geo, aes(lon, lat), fill = 'black', size = 4, shape = 1) +
  #https://aosmith.rbind.io/2020/07/09/ggplot2-override-aes/#suppress-aesthetics-from-part-of-the-legend
  guides(color = guide_legend(override.aes = list(size = c(1.5,1.5,1.5,1.5),
                                                  shape = c(NA, NA, NA, NA)))) +
  annotation_scale(location = "br") + 
  annotation_north_arrow(location = "tr", which_north = "true") 

```
:::

::: {style="position:absolute;top:20%;left:60%;"}
&#x25B2; Deployment sites<br>
{{< fa regular circle size=tiny >}} Last profile<br>
:::

## With a specific drifting configuration

::: {style="position:absolute;top:20%;"}
```{r, dumbbell plot}

df <- tibble(park_depth = c(200, 500, 1000),
             start = c(0.2,1.2,4.2),
             end = c(1,4,9),
             gap = c(0.8,3.8,4.8))

# df_text <- tibble(instrument = c('OST - 48', 'UVP - 72', 'OST - 144', 'UVP - 36', 'OST - 240', 'UVP - 60'),
#                   park_depth = c(175, 225, 475, 525, 975, 1025),
#                   start = c(.5,.5,2.5,2.5,6.5,6.5))

df_text <- tibble(instrument = c('OST - 30 min', 'UVP - 20 min', 'OST - 30 min', 'UVP - 2h', 'OST - 30 min', 'UVP - 2h'),
                  park_depth = c(150, 250, 450, 550, 950, 1050),
                  start = c(.5,.5,2.5,2.5,6.5,6.5))

other_annotation <- tibble(text = 'Optical window cleaning', 
                           start = c(1, 4, 9),
                           park_depth = c(200,500,1000))

fig <- plot_ly(df, color = I("#003366"))
fig |> add_segments(x = ~start, xend = ~end, y = ~park_depth, yend = ~park_depth, showlegend = F) |>
  add_markers(x = ~start, y = ~park_depth, color = I('#003366'), showlegend = F) |>
  add_markers(x = ~end, y = ~park_depth, color = I('#003366'), showlegend = F) |>
  layout(xaxis = list(title = 'Drifting time (days)', tickfont = list(size = 20), titlefont = list(size = 20)), yaxis = list(title = list(text = 'Parking depth (m)', standoff = 15L), tickfont = list(size = 20), 
                                                                                                             autorange="reversed", titlefont = list(size = 20), tickvals = c(200,500,1000, 2000)),
         shapes = list(list(type = 'line', x0 = 1, y0 = 200, x1 = 1.2, y1 = 500, line = list(dash = 'dash', color = 'black')),
                       list(type = 'line', x0 = 4, y0 = 500, x1 = 4.2, y1 = 1000, line = list(dash = 'dash', color = 'black')),
                       list(type = 'line', x0 = 0, y0 = 0, x1 = 0.2, y1 = 200, line = list(dash = 'dash', color = 'black')),
                       list(type = 'line', x0 = 9, y0 = 1000, x1 = 9.2, y1 = 2000, line = list(dash = 'dash', color = 'black')),
                       list(type = 'line', x0 = 9.2, y0 = 2000, x1 = 10, y1 = 0, line = list(dash = 'dash', color = 'black')))) |>
  config(displayModeBar = FALSE) |>
  add_trace(data = df_text, x = ~start, y = ~park_depth, type = 'scatter', mode = 'text', text = ~instrument, color = I('black')) |>
  add_annotations(x = other_annotation$start, y = other_annotation$park_depth, text = other_annotation$text, ax = 20) 
 
```
:::

## UVP6 particle abundance on profiling mode {.smaller}

::: {.panel-tabset}

### 0.1 - 0.5 mm

```{r, uvp6 profiling mode small part, fig.width=8, fig.height=5}


lpm_class <- c("NP_Size_102", "NP_Size_128", "NP_Size_161",
                         "NP_Size_203", "NP_Size_256", "NP_Size_323",
                         "NP_Size_406", "NP_Size_512", "NP_Size_645",
                         "NP_Size_813", "NP_Size_1020", "NP_Size_1290",
                        "NP_Size_1630", "NP_Size_2050")


particles <- all_floats |> filter(PhaseName == 'NPAR') |> select(juld, cycle, depth = pres, wmo, all_of(lpm_class), MLD) |> drop_na(NP_Size_102) |> dplyr::mutate(juld = as_date(juld))

particles_bis <- particles |> pivot_longer(cols = all_of(lpm_class), names_to = 'size', values_to = 'concentration') |> dplyr::mutate(size = size |> str_remove('NP_Size_') |> as.numeric()) 

# remove buggy data from float 4903634 (negative depth for some reason)
particles_bis <- particles_bis |> filter(depth >= 0)

# rel_conc
particles_bis <- particles_bis |> dplyr::group_by(wmo, size) |> dplyr::mutate(rel_conc = (concentration-min(concentration))/(max(concentration) - min(concentration)))

up_part <- particles_bis |> filter(depth < 2000, size < 512) |>
  #group_by(size) |>
  ggplot() + facet_grid(wmo~size) + theme_bw() +
  geom_point(aes(x=juld, y=depth, colour=log10(rel_conc)), size=1, shape=15) +
  scale_colour_viridis(option = 'A', limits = c(-2.5,-1), oob = scales::squish, na.value = 'grey', direction = -1) + 
  scale_y_reverse() +
  scale_x_date(labels = date_format("%m"), date_breaks = '3 month') +
  labs(colour = '#/L', x = 'Month', y = 'Depth (m)') 

up_part
```
::: {style="position:absolute;top:30%;left:65%;"}
Similar patterns across floats<br>
Unclear particle signature<br><br>
Rapid emptying in November<br><br>
Particle increase in April 
:::

### 0.5 - 2.5 mm

```{r, uvp6 profiling mode big part, fig.width=8, fig.height=5}

down_part <- particles_bis |> filter(depth < 2000, size >= 512) |>
  #group_by(size) |>
  ggplot() + facet_grid(wmo~size) + theme_bw() +
  geom_point(aes(x=juld, y=depth, colour=log10(rel_conc)), size=1, shape=15) +
  scale_colour_viridis(option = 'A', limits = c(-2.5,-1), oob = scales::squish, na.value = 'grey', direction = -1) + 
  scale_y_reverse() +
  labs(colour = '#/L', x = 'Month', y = 'Depth (m)') +
  #geom_vline(xintercept = as_date('2022-01-01')) +
  scale_x_date(labels = date_format("%m"), date_breaks = '3 month') 

down_part

```
::: {style="position:absolute;top:30%;left:65%;"}
Export event?
:::

### Float position

::: {style="position:absolute;top:20%;left:-15%;"}
```{r, float position ter}

p +
  geom_path(data = argo_map_geo, aes(lon, lat, colour = WMO), linewidth = 1) + 
  geom_point(data = argo_map_geo, aes(x= lon, y = lat, colour = WMO), size = 2) +
  #scale_color_brewer(palette = 'Dark2') + 
  scale_colour_manual(values = c('#D95F02', '#7570B3', '#E6AB02', '#1B9E77')) +
  theme_bw() +
  geom_point(data = transform_coord(argo_map_first), aes(lon, lat), shape = 17, size = 3) +
  geom_point(data = argo_map_last_geo, aes(lon, lat, colour = WMO), size = 4) +
  geom_point(data = argo_map_last_geo, aes(lon, lat), fill = 'black', size = 4, shape = 1) +
  #https://aosmith.rbind.io/2020/07/09/ggplot2-override-aes/#suppress-aesthetics-from-part-of-the-legend
  guides(color = guide_legend(override.aes = list(size = c(1.5,1.5,1.5,1.5),
                                                  shape = c(NA, NA, NA, NA)))) +
  annotation_scale(location = "br") + 
  annotation_north_arrow(location = "tr", which_north = "true") 

```
:::

:::

## UVP6 particle abundance on drifting mode {.smaller}

```{r, mean uvp data}

uvp_data <- all_floats |> filter(PhaseName == 'PAR') |> dplyr::mutate(month = month(juld), week = week(juld), DOY = yday(juld), short_date = ymd(juld)) |> select(juld, month, week, DOY, short_date, cycle, wmo, park_depth, all_of(lpm_class)) |> 
  drop_na(NP_Size_102) |> dplyr::mutate(juld = as_date(juld), WMO = factor(wmo))

uvp_data <- uvp_data |> pivot_longer(cols = lpm_class, names_to = 'size', values_to = 'conc') |> dplyr::mutate(size = size |> str_remove('NP_Size_') |> as.numeric())

# compute daily mean chla for each float at each cycle and at each drifting depth
mean_uvp_data <- uvp_data |> dplyr::group_by(cycle, WMO, size, park_depth, juld) |> dplyr::summarize(mean_conc = mean(conc, na.rm=T))

```

::: {.panel-tabset}

### 200 m

```{r, uvp drifting 200 m, fig.width=8, fig.height=5}

# add blank
# blank_data <- tibble(cycle = c(NA, NA), WMO = rep(as.factor(4903634),2), size = c(102,102), park_depth = c('200 m', '500 m'),
#                      juld = rep(as.Date('2023-04-05'),2), mean_conc = c(NA,NA))

#mean_uvp_data <- rbind(mean_uvp_data, blank_data)

fig200m <- mean_uvp_data |> filter(park_depth == '200 m') |> ggplot() + geom_point(aes(juld, mean_conc, colour = WMO, shape = WMO)) +
  geom_smooth(aes(juld, mean_conc), colour = 'black') +
  #scale_color_brewer(palette = 'Dark2') + 
  scale_colour_manual(values = c('#D95F02', '#7570B3', '#E6AB02', '#1B9E77')) +
  scale_x_date(labels = date_format("%m"), date_breaks = '2 month') +
  theme_bw() + labs(x = 'Month', y = 'Particle abundance (#/L)') +
  scale_y_continuous(trans = 'log10') +
  facet_wrap(~size, scales = 'free_y') 

fig200m
```

::: {style="position:absolute;top:30%;left:65%;"}
~~Drifting~~ from January to March
:::


### 500 m

```{r, uvp drifting 500 m, fig.width=8, fig.height=5}

mean_uvp_data |> filter(park_depth == '500 m') |> ggplot() + geom_point(aes(juld, mean_conc, colour = WMO, shape = WMO)) +
  geom_smooth(aes(juld, mean_conc), colour = 'black') +
  #scale_color_brewer(palette = 'Dark2') + 
  scale_colour_manual(values = c('#D95F02', '#7570B3', '#E6AB02', '#1B9E77')) +
  scale_x_date(labels = date_format("%m"), date_breaks = '2 month') +
  theme_bw() + labs(x = 'Month', y = 'Particle abundance (#/L)') +
  scale_y_continuous(trans = 'log10') +
  facet_wrap(~size, scales = 'free_y') 

```

::: {style="position:absolute;top:30%;left:65%;"}
~~Drifting~~ from February to March<br><br>
Increase in April
:::

### 1000 m

```{r, uvp drifting 1000 m, fig.width=8, fig.height=5}

mean_uvp_data |> filter(park_depth == '1000 m') |> ggplot() + geom_point(aes(juld, mean_conc, colour = WMO, shape = WMO)) +
  geom_smooth(aes(juld, mean_conc), colour = 'black') +
  #scale_color_brewer(palette = 'Dark2') + 
  scale_colour_manual(values = c('#D95F02', '#7570B3', '#E6AB02', '#1B9E77')) +
  scale_x_date(labels = date_format("%m"), date_breaks = '2 month') +
  theme_bw() + labs(x = 'Month', y = 'Particle abundance (#/L)') +
  scale_y_continuous(trans = 'log10') +
  facet_wrap(~size, scales = 'free_y') 

```

::: {style="position:absolute;top:30%;left:65%;"}
Similar measurements across floats<br><br>
Latent dynamics of the system?
:::

### Float position

::: {style="position:absolute;top:20%;left:-15%;"}
```{r, float position uvp6 drift}

p +
  geom_path(data = argo_map_geo, aes(lon, lat, colour = WMO), linewidth = 1) + 
  geom_point(data = argo_map_geo, aes(x= lon, y = lat, colour = WMO), size = 2) +
  #scale_color_brewer(palette = 'Dark2') + 
  scale_colour_manual(values = c('#D95F02', '#7570B3', '#E6AB02', '#1B9E77')) +
  theme_bw() +
  geom_point(data = transform_coord(argo_map_first), aes(lon, lat), shape = 17, size = 3) +
  geom_point(data = argo_map_last_geo, aes(lon, lat, colour = WMO), size = 4) +
  geom_point(data = argo_map_last_geo, aes(lon, lat), fill = 'black', size = 4, shape = 1) +
  #https://aosmith.rbind.io/2020/07/09/ggplot2-override-aes/#suppress-aesthetics-from-part-of-the-legend
  guides(color = guide_legend(override.aes = list(size = c(1.5,1.5,1.5,1.5),
                                                  shape = c(NA, NA, NA, NA)))) +
  annotation_scale(location = "br") + 
  annotation_north_arrow(location = "tr", which_north = "true") 

```
:::

:::

## OST particle flux on drifting mode {.smaller}

::: {.panel-tabset}

### OST

```{r, ost carbon fluxes, fig.width=8, fig.height=5}

plot_jumps_STATIC <- function(data){
  
  # make sure that the cp signal is in chronological order
  tmp <- data |> arrange(dates)
  
  # despike cp data with a 7-point moving window
  tmp$cp <- despike(tmp$cp, k = 3)
  
  # smooth cp data with a 3-point moving median, n time(s)
  tmp$cp <- slide(tmp$cp, fun = median, k = 3, n = 1, na.rm=T)
  
  # compute slope between two adjacent points (except first point) # we could start after 1h to let the float stabilize
  delta_x <- as.numeric(tmp$dates - lag(tmp$dates), units = 'days')
  delta_y <- tmp$cp - lag(tmp$cp)
  tmp$slope <- delta_y/delta_x
  
  # compute a Z score (assuming a normal distribution of the slopes) on the slopes
  tmp <- tmp |> dplyr::mutate(zscore = (slope - mean(slope, na.rm = T))/sd(slope, na.rm = T))
  
  # spot outliers on the Z score signal
  # interquartile range between Q25 and Q75 -> had to used that and not the despike function because slopes are often close (or equal) to 0 so it can miss clear jumps. Q25 and Q75 are more trustworthy in this case than the despike function of Jean-Olivier (see package castr on his github: https://github.com/jiho/castr)
  IQR <- quantile(tmp$zscore, probs = 0.75, na.rm=T) - quantile(tmp$zscore, probs = 0.25, na.rm=T)
  # outliers ('spikes' in the Z score signal)
  spikes_down <- tmp$zscore < quantile(tmp$zscore, 0.25, na.rm=T) - 1.5 *IQR
  spikes_up <-  tmp$zscore > quantile(tmp$zscore, 0.75, na.rm=T) + 1.5 *IQR
  spikes <- as.logical(spikes_down + spikes_up)
  
  # IQR <- quantile(tmp$slope, probs = 0.75, na.rm=T) - quantile(tmp$slope, probs = 0.25, na.rm=T)
  # # outliers ('spikes' in the Z score signal)
  # spikes_down <- tmp$slope < quantile(tmp$slope, 0.25, na.rm=T) - 1.5 *IQR
  # spikes_up <-  tmp$slope > quantile(tmp$slope, 0.75, na.rm=T) + 1.5 *IQR
  # spikes <- as.logical(spikes_down + spikes_up)
  
  # assign spikes
  tmp$spikes <- spikes
  
  # assign colour code to cp signal
  tmp$colour <- 'base signal' # base signal = smoothed despiked cp signal
  tmp[which(tmp$spikes == TRUE),]$colour <- 'jump'
  
  # add group to compute the slope of each group of points, separated by a jump
  tmp$group <- NA
  
  # index of jumps in the array
  jump_index <- which(tmp$colour == 'jump')
  
  # assign group identity to each group of points, separated by a jump (= subgroup)
  for (i in jump_index){
    for (j in 1:nrow(tmp)){
      if ((j < i) & (is.na(tmp$group[j]))){
        tmp$group[j] <- paste0('group_',i)
      }
    }
  }
  tmp$group[which(is.na(tmp$group))] <- 'last_group'
  
  # compute slope for each subgroup
  slope_df <- tmp |> filter(colour == 'base signal', slope != 'NA') |> dplyr::group_by(group) |> dplyr::summarise(min_time = min(dates), max_time = max(dates), 
                                                                                                                  nb_points = n(), first_cp = cp[1], last_cp = cp[nb_points],
                                                                                                                  delta_x = as.numeric(difftime(max_time, min_time, units = 'days')),
                                                                                                                  delta_y = (last_cp-first_cp)*0.25, slope = delta_y/delta_x) # *0.25 to convert cp to ATN
  
  # remove negative slope from the mean slope (no physical meaning)
  slope_df <- slope_df |> filter(slope > 0)
  
  # remove if only one point (cannot fit a slope with one point) -> switched to 3 points
  slope_df <- slope_df |> filter(nb_points > 3)
  
  # compute weighted average slope (to take into account the fact that some subgroups might have 2 points and a high slope vs. large group of points with a small slope)
  mean_slope <- sum(slope_df$nb_points * slope_df$slope)/sum(slope_df$nb_points)
  
  # convert cp to POC using Estapa's relationship 
  poc_flux <- 633*(mean_slope**0.77) # /!\ slope computed for ATN on y axis (delta_y *0.25 because ATN = cp*0.25) -> should be OK
  
  # build dataframe to plot each subgroup
  part1 <- slope_df |> select(group, time = min_time, cp = first_cp)
  part2 <- slope_df |> select(group, time = max_time, cp = last_cp)
  part_slope <- rbind(part1, part2)
  
  # spot negative jump
  tmp$colour[which((tmp$colour == 'jump') & (tmp$slope < 0))]  <- 'negative jump'
  
  # add large particles flux to the party
  rows_to_keep <- c(jump_index, jump_index-1)
  tmp2 <- tmp[rows_to_keep,] |> select(dates, cp, slope, colour, group) |> arrange(dates)
  
  # remove negative jumps, if any
  check_colour <- unique(tmp2$colour)
  if(length(check_colour) >= 2){ # there is a least a jump (positive or negative)
    tmp2 <- tmp2 |> dplyr::mutate(diff_jump = cp - lag(cp)) 
    even_indexes <- seq(2,nrow(tmp2),2)
    tmp2 <- tmp2[even_indexes,]
  }else{ # No jump
    tmp2 <- NULL
  }
  
  if(is.null(tmp2)){ # no jump
    large_part_poc_flux <- 0
    tmp3 <- NULL
  }else{
    tmp3 <- tmp2 |> filter(diff_jump > 0)
    if(nrow(tmp3) == 0){ # no positive jumps
      large_part_poc_flux <- 0
    }else{
      delta_y <- sum(tmp3$diff_jump) *0.25 # to get ATN (= cp*0.25)
      max_time <- max(tmp$dates)
      min_time <- min(tmp$dates)
      delta_x <- as.numeric(difftime(max_time, min_time, units = 'days'))
      slope_large_part <- delta_y/delta_x
      large_part_poc_flux <- 633*(slope_large_part**0.77)
    }
  }
  
  # compute total drifting time
  max_time <- max(tmp$dates)
  min_time <- min(tmp$dates)
  drifting_time <- as.numeric(difftime(max_time, min_time, units = 'days'))
  
  # to plot subgroups
  part_slope_tmp <- part_slope |> dplyr::mutate(dates = time, colour = 'slope')
  
  # plot
  jump_plot <- plot_ly(tmp, x = ~dates, y = ~cp, type = 'scatter', mode = 'markers', color = ~colour, colors = c('#003366','#E31B23', '#FFC325')) |>
    add_lines(data= part_slope_tmp, x = ~dates, y = ~cp, split = ~group, color = I('#DCEEF3'), showlegend = F) |>
    layout(title= paste0('Drifting time: ', round(drifting_time,3), ' days\n',
                         'Mean ATN slope (light blue): ', round(mean_slope,3), ' day-1\n',
                         'POC flux (small particles): ', round(poc_flux,1), ' mg C m-2 day-1\n',
                         'POC flux (large particles): ', round(large_part_poc_flux,1), ' mg C m-2 day-1'), yaxis = list(title = 'Cp (1/m)'), xaxis = list(title = 'Time'))
  
  #return(jump_plot)
  #return(list('jump_plot' = jump_plot, 'jump_table' = tmp3))
  
    # adapt script to return large and small flux
  df <- tibble('max_time' = max_time, 'min_time' = min_time, 'small_flux' = poc_flux, 'large_flux' = large_part_poc_flux, park_depth = data$park_depth[1], wmo = data$wmo[1],
               cycle = data$cycle[1])
  
  return(df)
  #return(jump_plot)
  
}

# remove bad data from float 6904241
float_6904241_slope <- float_6904241 |> filter(cycle < 20)
# create dataframe for all drifting data (for all floats)
all_floats_slope <- rbind(float_4903634, float_6904240, float_6904241_slope, float_1902578)
all_floats_slope <- all_floats_slope |> filter(PhaseName == 'PAR') |> drop_na(cp) |> select(depth = pres, cp, dates = juld, park_depth, wmo, cycle) |>
   dplyr::mutate(wmo = factor(wmo, levels = c(6904240,4903634,6904241,1902578)),
          park_depth = factor(park_depth, levels = c('200 m', '500 m', '1000 m')))

# start loop for all data
wmo <- c(4903634, 6904240, 6904241, 1902578)
park_depth <- c('200 m', '500 m', '1000 m')

res <- data.frame()
for (i in wmo){
  max_cycle <- as.numeric(all_floats_slope |> filter(wmo == i) |> dplyr::summarise(max_cycle = max(cycle)))
  for (j in park_depth){
    for (k in seq(1:max_cycle)){
      tmp <- all_floats_slope |> filter(wmo == i, park_depth == j, cycle == k)
      if(nrow(tmp) == 0){
        next
      }else if(nrow(tmp) < 3){ # case where there is not enough data
        next
      }else{
          output <- plot_jumps_STATIC(tmp)
          res <- rbind(res, output)
      }
    }
  }
}

# keep the good fluxes
cflux <- res |> dplyr::mutate(drifting_time = difftime(max_time, min_time, units = 'days'), WMO = factor(wmo))

cflux_info_table <- cflux |> dplyr::group_by(park_depth) |> summarize(min_smallf = min(small_flux, na.rm=T), max_smallf = max(small_flux, na.rm=T),
                                                                mean_smallf = mean(small_flux, na.rm=T), median_smallf = median(small_flux, na.rm=T),
                                                                std_smallf = sd(small_flux, na.rm=T),
                                                                min_largef = min(large_flux, na.rm=T), max_largef = max(large_flux, na.rm=T),
                                                                mean_largef = mean(large_flux, na.rm=T), median_largef = median(large_flux, na.rm=T),
                                                                std_largef = sd(large_flux, na.rm=T))

cflux$date <- as_date(cflux$min_time)

## plot it

# add black data to have the same x axis for all drifting depths (to show that we stopped the drifting at 200 and 500 m)
blank_data <- tibble(max_time = c(NA, NA), min_time = c(NA,NA), small_flux = c(NA,NA), large_flux = c(NA,NA), park_depth = c('200 m', '500 m'),
                     wmo = rep(4903634,2), cycle = c(NA,NA), drifting_time = c(NA,NA), WMO = rep(as.factor(4903634),2), date = rep('2023-04-05',2))

tmp <- rbind(cflux, blank_data)

up <- tmp |> ggplot(aes(x = date, y = small_flux)) +
    geom_point(data = tmp, aes(x = date, y = small_flux, colour = WMO, shape = WMO)) +
  geom_smooth(data = tmp, aes(x = date, y = small_flux), colour = 'black') +
  #scale_color_brewer(palette = 'Dark2') + 
  scale_colour_manual(values = c('#D95F02', '#7570B3', '#E6AB02', '#1B9E77')) +
  scale_x_date(labels = date_format("%m"), date_breaks = '2 month') +
  guides(fill=guide_legend(title="WMO")) +
  facet_wrap(~park_depth, scales = 'free') +
  labs(x = '', y = TeX('$F_{small}$ (mg C m$^{-2}$ day$^{-1}$)')) +
  scale_y_continuous(trans = 'log10') +
  theme_bw() 

down <- tmp |> ggplot(aes(x = date, y = large_flux)) +
  geom_point(data = tmp, aes(x = date, y = large_flux, colour = WMO, shape = WMO)) +
  geom_smooth(data = tmp, aes(x = date, y = large_flux), colour = 'black') +
  #scale_color_brewer(palette = 'Dark2') + 
  scale_colour_manual(values = c('#D95F02', '#7570B3', '#E6AB02', '#1B9E77')) +
  scale_x_date(labels = date_format("%m"), date_breaks = '2 month') +
  guides(fill=guide_legend(title="WMO")) +
  facet_wrap(~park_depth, scales = 'free') +
  labs(x = 'Month', y = TeX('$F_{large}$ (mg C m$^{-2}$ day$^{-1}$)')) +
  theme_bw() +
  scale_y_continuous(trans = 'log10') +
  theme(legend.position = 'none') 

up / down

```

### MLD

```{r, mld, fig.width=8, fig.height=5}
mld_data <- vroom('/home/flo/dox/ArgoShine/npq_corrected_data.csv')
# clean and smoothed chla data
mld_data <- mld_data |> select(cycle, MLD, pres, juld, wmo, chla_npq) |> dplyr::mutate(date = as_date(juld), WMO = factor(wmo, levels = c(6904240,4903634,6904241,1902578)))
mld_data <- mld_data |> group_by(date, WMO, pres, cycle) |> summarize(mean_chla = mean(chla_npq, na.rm=T), mld = unique(MLD))

# reverselog_trans <- function(base = exp(1)) {
#     trans <- function(x) -log(x, base)
#     inv <- function(x) base^(-x)
#     trans_new(paste0("reverselog-", format(base)), trans, inv, 
#               log_breaks(base = base), 
#               domain = c(1e-100, Inf))
# }
# 
# mld_plot <- ggplot(mld_data) + geom_line(aes(x = date, y = mld, colour = WMO)) +
#   labs(x = 'Month', y = 'MLD (m)') + scale_y_continuous(trans = reverselog_trans(10), breaks = c(10,50,200,400,750)) +
#   scale_color_brewer(palette = 'Dark2') + 
#   scale_x_date(labels = date_format("%m"), date_breaks = '1 month') + theme_bw()

# reverselog_trans <- function(base = exp(1)) {
#     trans <- function(x) -log(x, base)
#     inv <- function(x) base^(-x)
#     trans_new(paste0("reverselog-", format(base)), trans, inv, 
#               log_breaks(base = base), 
#               domain = c(1e-100, Inf))
# }

mld_plot <- ggplot(mld_data) + geom_line(aes(x = date, y = mld, colour = WMO), size = 1) +
  labs(x = 'Month', y = 'MLD (m)') + scale_y_reverse() +
  #scale_color_brewer(palette = 'Dark2') + 
  scale_colour_manual(values = c('#D95F02', '#7570B3', '#E6AB02', '#1B9E77')) +
  scale_x_date(labels = date_format("%m"), date_breaks = '1 month') + theme_bw() +
  geom_hline(yintercept = 200, colour = 'black', linetype = 'dashed') +
  geom_hline(yintercept = 500, colour = 'black', linetype = 'dashed')

mld_plot

```

### Chlorophyll a

```{r, chla, fig.width=8, fig.height=5}

# fetch data
npq_data <- vroom('/home/flo/dox/ArgoShine/npq_corrected_data.csv')

# clean and smoothed chla data
d <- npq_data |> select(cycle, MLD, pres, juld, wmo, chla_npq) |> dplyr::mutate(date = as_date(juld))
d <- d |> group_by(date, wmo, pres, cycle) |> summarize(mean_chla = mean(chla_npq, na.rm=T), mld = unique(MLD))
d <- d |> dplyr::mutate(smoothed_chla = smooth(mean_chla)/2) 

# remove NaN in smoothed chla
d <- d |> drop_na(smoothed_chla)

d$wmo <- factor(d$wmo, levels = c(6904240,4903634,6904241,1902578))

# compute chla integration in the MLD and in the 0-100 m zone
d_chla <- d |> group_by(wmo, date) |> summarize(chla_0_100m = integrate(smoothed_chla, pres, from=0, to=100),
                                       mld = unique(mld),
                                       chla_0_mld = integrate(smoothed_chla, pres, from = 0, to=mld),
                                       median_chla_0_20m = median(smoothed_chla[pres<=20], na.rm=T))
#
# ggplot(d_chla) + geom_point(aes(date, chla_0_100m)) + facet_wrap(~wmo, scales = 'free') + theme_bw() + labs(x = 'Month', y = 'Integrated Chla 0-100 m (CHLA UNITS)')
#ggplot(d_chla) + geom_point(aes(date, chla_0_mld)) + facet_wrap(~wmo, scales = 'free')

# add couple info
d_chla <- d_chla |> dplyr::mutate(group = if_else(wmo %in% c(6904240,4903634), '6904240 - 4903634', '6904241 - 1902578'))

chla_mld <- d_chla |> drop_na(chla_0_100m)

chla_plot_mld <- ggplot(chla_mld) + geom_line(aes(x = date, y = chla_0_mld, colour = as.factor(wmo)), linewidth = 1) + labs(x = 'Month', y = TeX('Integrated Chla content (mg m$^{-2}$)'), colour = 'WMO') +
  theme_bw() + scale_x_date(labels = date_format("%m"), date_breaks = '1 month') +
  #scale_colour_manual(values = c('#003366', '#E31B23'))
  #scale_color_brewer(palette = 'Dark2') 
 scale_colour_manual(values = c('#D95F02', '#7570B3', '#E6AB02', '#1B9E77'))

chla_plot_100m <- ggplot(chla_mld) + geom_line(aes(x = date, y = chla_0_100m, colour = as.factor(wmo)), linewidth = 1) + labs(x = 'Month', y = TeX('Integrated Chla content (mg m$^{-2}$)'), colour = 'WMO') +
  theme_bw() + scale_x_date(labels = date_format("%m"), date_breaks = '1 month') +
  #scale_color_brewer(palette = 'Set3') + 
 scale_colour_manual(values = c('#D95F02', '#7570B3', '#E6AB02', '#1B9E77')) +
  theme(legend.position = 'none')

chla_plot_mld / chla_plot_100m

```
::: {style="position:absolute;top:30%;left:65%;"}
Top --- integration over MLD<br>
Bottom --- integration over 100 m
:::

### Float position

::: {style="position:absolute;top:20%;left:-15%;"}
```{r, float position bis}

p +
  geom_path(data = argo_map_geo, aes(lon, lat, colour = WMO), linewidth = 1) + 
  geom_point(data = argo_map_geo, aes(x= lon, y = lat, colour = WMO), size = 2) +
  #scale_color_brewer(palette = 'Dark2') + 
  scale_colour_manual(values = c('#D95F02', '#7570B3', '#E6AB02', '#1B9E77')) +
  theme_bw() +
  geom_point(data = transform_coord(argo_map_first), aes(lon, lat), shape = 17, size = 3) +
  geom_point(data = argo_map_last_geo, aes(lon, lat, colour = WMO), size = 4) +
  geom_point(data = argo_map_last_geo, aes(lon, lat), fill = 'black', size = 4, shape = 1) +
  #https://aosmith.rbind.io/2020/07/09/ggplot2-override-aes/#suppress-aesthetics-from-part-of-the-legend
  guides(color = guide_legend(override.aes = list(size = c(1.5,1.5,1.5,1.5),
                                                  shape = c(NA, NA, NA, NA)))) +
  annotation_scale(location = "br") + 
  annotation_north_arrow(location = "tr", which_north = "true") 

```
:::

:::

## OST vs. UVP6 carbon flux estimations {.smaller}

::: {.panel-tabset}

### Carbon fluxes

```{r, ost vs UVP6, fig.width=7, fig.height=5}

compute_flux <- function(A, b, PSD){ # PSD = Particle Size Distribution
  # for classes sizes between 0.25 mm and 1.5 mm
  mid_ESD <- c(0.29042685,
               0.36591491, 0.46102389, 0.58085371, 0.73182981, 0.92204779,
               1.16170742, 1.46365963) # With Lionel's script
  exp <- A * mid_ESD ** b
  estimated_flux <- rowSums(t(t(PSD)*exp))
  return(estimated_flux)
}

parking_data <- rbind(float_4903634, float_6904240, float_6904241_slope, float_1902578)
parking_data <- parking_data |> filter(PhaseName == 'PAR') |> drop_na(NP_Size_102) |> select(park_depth, all_of(lpm_class), dates = juld, park_depth, wmo, cycle) |> dplyr::mutate(wmo = factor(wmo, levels = c(6904240,4903634,6904241,1902578)),
                                   park_depth = factor(park_depth, levels = c('200 m', '500 m', '1000 m')))
parking_spectra <- parking_data |> dplyr::select(NP_Size_256:NP_Size_1290)

parking_data <- parking_data |> dplyr::mutate(guidi_flux = compute_flux(12.5, 3.81, parking_spectra)) #|> group_by(park_depth, cycle, wmo) 

# add rainer computation
compute_flux_rainer <- function(A, b, PSD){
  
  # Rainer uses an ESD in cm ..
  mid_ESD <- c(0.11525597, 0.14521343, 0.18295745, 0.23051195, 0.29042685,
       0.36591491, 0.46102389, 0.58085371, 0.73182981, 0.92204779,
       1.16170742, 1.46365963, 1.84409558, 2.32341484) / 10
  exp <- A * mid_ESD ** b # because Rainer uses the units of particles/m3 and not particles/L
  estimated_flux <- rowSums(t(t(PSD)*exp))
  return(estimated_flux)
}

parking_spectra_rainer <- parking_data |> dplyr::select(lpm_class)
parking_data <- parking_data |> dplyr::mutate(rainer_flux = compute_flux_rainer(2.8649, 2.24, parking_spectra_rainer)) 
parking_data <- parking_data |> dplyr::mutate(iversen_flux = compute_flux(273, 4.27, parking_spectra)) 

# plot it
comparison_flux_ost_uvp <- merge(parking_data, cflux) |> dplyr::mutate(total_flux = small_flux + large_flux)

# add guidi flux using fminsearch using the optimize function of scipy in python (see a paper of someoe who did it, see Giering 2020 ou willimaoson et giering 2022)
comparison_flux_ost_uvp <- comparison_flux_ost_uvp |> dplyr::mutate(guidi_flux_fminsearch = compute_flux(21.98, 1.18, parking_spectra))

# https://stackoverflow.com/questions/41077199/how-to-use-r-ggplot-stat-summary-to-plot-median-and-quartiles
ggplot(comparison_flux_ost_uvp) + geom_line(aes(x = date, y = total_flux), colour = 'black') + facet_wrap(~wmo~park_depth, scales = 'free_y', nrow = 4) +
  geom_errorbar(aes(x = date, y = guidi_flux),
                      stat = 'summary',
                      #fun.min = function(z) {quantile(z, 0.25)},
                      #fun.max = function(z) {quantile(z, 0.75)},
                      fun = median, colour = '#4774c5', width = 5) +
    geom_line(aes(x = date, y = guidi_flux),
                      stat = 'summary',
                      fun = median, colour = '#4774c5') +
    geom_errorbar(aes(x = date, y = iversen_flux),
                      stat = 'summary',
                      #fun.min = function(z) {quantile(z, 0.25)},
                      #fun.max = function(z) {quantile(z, 0.75)},
                      fun = median, colour = '#D01556FF', width = 5) + # #003366
    geom_line(aes(x = date, y = iversen_flux),
                      stat = 'summary',
                      fun = median, colour = '#D01556FF') + 
  scale_y_continuous(trans = 'log10') + theme_bw() + labs(x = 'Month', y = TeX('$F_{total}$ (mg C m$^{-2}$ day$^{-1}$)')) +
  scale_x_date(labels = date_format("%m"), date_breaks = '1 month')

```

::: {style="position:absolute;top:30%;left:56%;"}
```{=tex}
\begin{gather*}
F_{total,~OST} = F_{small} + F_{large}
\end{gather*}
```
:::

::: {style="position:absolute;top:40%;left:56%;"}
```{=tex}
\begin{gather*}
F_{total,~UVP} = \sum_{i}^{N}C_{i}Ad_{i}^{B}
\end{gather*}
```
:::

::: {style="position:absolute;top:60%;left:57%;"}
<span style="color: #4774c5;">Guidi et al., (2008) --- (A, B) = (12.5, 3.81)</span><br>
<span style="color: #D01556FF;">Iversen et al., (2010) --- (A, B) = (273.8, 4.27)</span><br>

:::


### Correlations

```{r, flux correlations}

correlations <- comparison_flux_ost_uvp |> dplyr::select(park_depth, wmo, cycle, guidi_flux, small_flux, large_flux, date, total_flux) |> dplyr::group_by(wmo, park_depth, cycle) |> dplyr::mutate(median_guidi_flux = median(guidi_flux)) |> dplyr::group_by(park_depth, wmo) |> dplyr::summarize(cor_small = round(cor(median_guidi_flux, small_flux),2), cor_large = round(cor(median_guidi_flux, large_flux),2), cor_total = round(cor(median_guidi_flux, total_flux),2))

correlations <- correlations |> pivot_wider(names_from = park_depth, values_from = c(cor_small, cor_large, cor_total))

gt(correlations) |> tab_spanner(label = "Small flux", columns = 2:4) |> tab_spanner(label = "Large flux", columns = 5:7) |> tab_spanner(label = 'Total flux', columns = 8:10) |>
  cols_label(wmo = 'WMO', `cor_small_200 m` = '200 m',
             `cor_small_500 m` = '500 m',
             `cor_small_1000 m` = '1000 m',
             `cor_large_200 m` = '200 m',
             `cor_large_500 m` = '500 m',
             `cor_large_1000 m` = '1000 m',
             `cor_total_200 m` = '200 m',
             `cor_total_500 m` = '500 m',
             `cor_total_1000 m` = '1000 m') |>
  # data_color(rows = 1:4,
  #            columns = 2:10,
  #            palette = c("#1984c5", "#22a7f0", "#63bff0", "#a7d5ed", "#e2e2e2", "#e1a692", "#de6e56", "#e14b31", "#c23728"),
  #            direction = "row")
  tab_style_body(
    style = cell_fill(color = "#22a7f0"),
    values = c(-0.05, -0.02, -0.02, 0.06, 0.06)
  ) |>
    tab_style_body(
    style = cell_fill(color = "#e14b31"),
    values = c(0.78, 0.72,0.83,0.75,0.78,0.86,0.76,0.83,0.77,0.78,0.81,0.87,0.84,0.7,0.87,0.74,0.82)
  ) |>
  grand_summary_rows(
    columns = 2:10,
    fns = list(
      average ~ round(mean(.),2),
      sd ~ round(sd(.), 2)
    )
  ) |>
  tab_options(
    grand_summary_row.background.color = "lightgray"
  ) 


```
:::

## {{< fa check >}} Take-home message #2

- OST and UVP6 are well correlated, especially at 500 and 1000 m
- Preliminary results
- etc etc etc Ã  discuter avec HervÃ© et Lionel

# CONVERSE {background-color="black"}

**CON**tinuous **VE**rtical **SE**questration

## {{< fa bell >}} BCP and its export pathways

```{r, bcp and its export pathways for converse, fig.width=6, fig.height=6}

# df <- tibble(pump = c('BGP', 'BGP', 'VMP diel', 'VMP diel', 'VMP seasonal', 'VMP seasonal', 'Mixed layer', 'Mixed layer', 'Eddy subduction', 'Eddy subduction', 'Large-scale subduction', 'Large-scale subduction'),
#              group = c(rep('BGP', 2), rep('VMP', 4), rep('Mixing', 6)),
#              #type = c('POC', 'DOC','POC', 'DOC','POC', 'DOC','POC', 'DOC','POC', 'DOC','POC', 'DOC'),
#              #start = c(0, NA, 200, NA, 600, NA, 200, 200, 150, 150, 200, 200),
#              #start = rep(0,12),
#              end = c(2500, NA, 600, NA, 1400, NA, 1000, 1000, 400, 400, 1000, 1000),
#              depth = c(0, 100, 200, 300, 500, 750, 1000, 1250, 1500, 1750, 2000, 2500))


df <- tibble(pump = c('BGP', 'VMP diel', 'VMP seasonal', 'Mixed layer','Eddy subduction', 'Large-scale subduction'),
             group = c(rep('BGP', 1), rep('VMP', 2), rep('Mixing', 3)),
             end = c(2500, 600, 1400, 1000, 400, 1000),
             depth = c(0, 100, 500, 1000, 1500, 2500))

plot_ly(df, x = ~pump, y = ~end, type = 'bar', color = ~group, colors = c("#f5e8c8", "#e01f54", '#001852'), showlegend = F) |>
  layout(xaxis = list(title = 'Pumps', tickfont = list(size = 20), titlefont = list(size = 20), showgrid = F), 
          yaxis = list(title = list(text = 'Depth (m)', standoff = 15L), barmode = "group", autorange="reversed", tickfont = list(size = 20), titlefont = list(size = 20), showgrid = T,
          tickmode = "array", tickvals = c(400,1000,1400), ticktext = c("400","1000","1400"))) |> config(displayModeBar = FALSE)

# plot_ly(df, x = ~group, y = ~start, type = 'scatter', mode = 'markers', marker = list(color = 'white', showlegend = F)) |>
#   add_trace(y = ~end, mode = 'markers', showlegend = F) |>
#    add_segments(x = 'BGP', xend = 'BGP', y = 0, yend = 2500, line = list(width = 15, color = "#f5e8c8"), showlegend = F) |>
#   add_segments(x = 'VMP diel', xend = 'VMP diel', y = 200, yend = 600, line = list(width = 15, color = "#001852"), showlegend = F) |>
#   add_segments(x = 'VMP seasonal', xend = 'VMP seasonal', y = 600, yend = 1400, line = list(width = 15, color = "#001852"), showlegend = F) |>
#   add_segments(x = 'Eddy subduction', xend = 'Eddy subduction', y = 150, yend = 400, line = list(width = 15, color = "#e01f54"), showlegend = F) |>
#   add_segments(x = 'Mixed layer', xend = 'Mixed layer', y = 200, yend = 1000, line = list(width = 15, color = "#e01f54"), showlegend = F) |>
#   add_segments(x = 'Large-scale subduction', xend = 'Large-scale subduction', y = 200, yend = 1000, line = list(width = 15, color = "#e01f54"), showlegend = F) |>
#    layout(xaxis = list(title = 'Pumps', tickfont = list(size = 20), titlefont = list(size = 20), showgrid = T), 
#           yaxis = list(title = list(text = 'Depth (m)', standoff = 15L), autorange="reversed", tickfont = list(size = 20), titlefont = list(size = 20), showgrid = T,
#           tickmode = "array", tickvals = c(400,1000,1400), ticktext = c("400","1000","1400"))) |> config(displayModeBar = FALSE) #|>
#   #add_trace(y = 2500, type = 'scatter', mode = 'line', line = list(color = 'black', dash = 'dash'), showlegend = F) 


```

::: {style="position:absolute;top:15%;left:45%;"}
POC (all) and DOC (<span style="border-bottom: 4px solid red;">mixing</span>)<br><br>
Gravitational settling or injection<br><br>
Mixing + VMP merge back with BGP
:::

## Sequestration can occur at any depth

![](converse/converse_fig1.svg){.absolute top=80 left=0 width="420" height="600" .my-image}

::: {style="position:absolute;top:12%;left:40%;"}

<span style="font-size: 30px;">BCP = BGP + VMP + Mixing pumps transport <span style="color: #528133;"><strong>F<sub>org</sub></strong></span><br><br></span> 
<span style="font-size: 30px;"><span style="color: #528133;"><strong>F<sub>org</sub></strong></span> respired to CO<sub>2</sub> (<strong><span style="color: #D01556FF;"><strong>F<sub>remin</sub></strong></span></strong>) or sedimented <br><br></span>
<span style="font-size: 30px;">Respiratory CO<sub>2</sub> = biogenic DIC (<strong><span style="color: #793da5;"><strong>DIC<sub>bio</sub></strong></span></strong>)<br><br></span>
<span style="font-size: 30px;"><strong><span style="color: #793da5;"><strong>DIC<sub>bio</sub></strong></span> </strong> in the ocean for $\geq$ 100 years = sequestered (<strong><span style="color: #4774c5;"><strong>F<sub>seq</sub></strong></span></strong>)<br><br></span>
<span style="font-size: 30px;">Flux ~~inventory~~ &#8594; Pg C year<sup>-1</sup><br><br></span> 
<span style="font-size: 30px;">Continuous vs. fixed sequestration depth (e.g. 1000 m)<br><br></span> 
<!-- <span style="font-size: 30px;"><span style="color: #528133;"><strong>F<sub>org</sub></strong></span> reaching sediment = very long-term sequestration<br><br></span> -->
:::

::: {style="position:absolute;top:92%;left:0%;"}
<span style="font-size: 30px;"><span style="color: gray;">Ricour et al., (2023)</span> 
:::

## How can we compute F<sub>seq</sub> ?

![](converse/fig2_converse.svg){.absolute top=80 left=-80 width="800" height="600"}

::: {style="position:absolute;top:15%;left:60%;"}

<span style="font-size: 30px;">f<sub>100</sub> --- <em>fraction of a water parcel at a given location and depth that will remain in the ocean for $\geq$ 100 years</em><br><br></span> 
<span style="font-size: 30px;">OCIM model <span style="color: gray;">(Siegel et al., 2021)</span><br><br>
<span style="font-size: 30px;">f<sub>100 (avg)</sub> (530 m) = 0.3<br></span>
<span style="font-size: 30px;">f<sub>100 (avg)</sub> (> 1000 m) = 0.87<br><br></span>
 
::: {.box}
<span style="font-size: 30px;">F<sub>seq</sub> = f<sub>100</sub> x F<sub>remin</sub><br></span>
:::

:::

## 7 CONVERSE versions to compute F<sub>remin</sub> {.smaller}

<!-- ![](converse/Fig4_PHDPREZ.svg){.absolute top=40 left=-60 width="800" height="800"} -->

::: {style="position:absolute;top:15%;left:0%;"}
```{r, converse Fremin}

df <- data.frame(version = c('C1', 'C2', 'C3', 'C4', 'C5', 'C6'),
            b_factor = c(0.86, 'Variable', 'Regional', '', '', 0.86),
            export_depth = c(100, 100, 100, 'Zeu', 100, 100),
            export_value = c(3,3,3,8.6,7.3,3),
            group = c('Group 1', 'Group 1', 'Group 1', 'Group 2', 'Group 2', 'Group 3'),
            BGP = c('empirical', 'empirical', 'empirical', 'model', 'model', 'export ratio'),
            Mixing = c('export ratio', 'export ratio', 'export ratio', 'model', 'model', 'export ratio'),
            VMP = rep('empirical', 6))
            # bgp = rep('f(pixel, depth layer, C#)', 7),
            # bgp = 'f(pixel, depth layer, C#)',
            # mixing = rep('f(pixel, depth layer, C#)', 7),
            # vmp = rep('f(pixel, C#)', 7))
# 
# # df_transposed <- tibble::as_tibble(t(df))
# # colnames(df_transposed) <- df_transposed[1,]
# # df<- df_transposed[-1,]
# # 
# # rownames(df) <- c('b', 'Export depth', 'Export total flux')
# 
df |> group_by(group) |>
  gt() |>
  cols_label(version = md('**Version**'),
             b_factor = md('**b**'),
             export_depth = md('**Export depth <br>(m)**'),
             export_value = md('**Export value <br>(Pg C year<sup>-1</sup>)**'),
             BGP = md('**BGP**'),
             Mixing = md('**Mixing**'),
             VMP = md('**VMP**')) |>
  cols_align("center") |>
  tab_footnote(footnote = 'C7 ~ C1 except for the mixing pump', locations = cells_column_labels(version))


# flextable(df) |> merge_at(i = 1:3, j = 3) |>
#   merge_at(i = 1:3, j = 4) |>
#   align_text_col(align = "center", header = TRUE, footer = FALSE)|>
#   hline(i = 3, j = 1:5)


```

:::

::: {style="position:absolute;top:15%;left:60%;"}
<span style="font-size: 30px;">F<sub>remin</sub> = f(pixel, depth layer, C#)<br><br></span>
<span style="font-size: 30px;">BGP empirical --- Martin's flux attenuation curve<br><br></span>
<span style="font-size: 30px;">Mixing --- 3-in-1<br><br></span>
<span style="font-size: 30px;">VMP diel --- migration at 300 m<br></span>
<span style="font-size: 30px;">VMP seasonal --- migration at 600 m<br>(NNA only)</span>
<!-- $$F_{orgPOC}(z) = F_{expPOC} \times \left(\frac{z}{z_{exp}}\right)^{-b}$$ -->
<!-- $$F_{reminPOC}(\Delta z) = F_{orgPOC}(z) - F_{orgPOC}(z+1)$$ -->
:::

## Examples of stations --- <span style="color: #D01556FF;">F<sub>remin</sub></span> x <span style="color: #E6AB02;">f<sub>100</sub></span> = <span style="color: #4774c5;">F<sub>seq</sub></span>

![](converse/Fig4_PHDPREZ.svg){.absolute top=40 left=-80 width="800" height="800"} 

::: {style="position:absolute;top:15%;left:60%;"}

<span style="font-size: 30px;"><span style="color: #4774c5;">F<sub>seq</sub></span> max above 2000 m<br><br></span>
<span style="font-size: 30px;">50% of F<sub>seq</sub> accumulation by 1000 m<br><br></span>
<span style="font-size: 30px;">Fixed sequestration depth = missing most of <span style="color: #4774c5;">F<sub>seq</sub></span><br><br></span>
<!-- <span style="font-size: 30px;">Next step --- Global estimations (= all pixels)<br><br></span> -->
:::

## Global F<sub>seq</sub> --- continuous vs. fixed depth 

![](converse/Fig5PREZ.jpg.svg){.absolute top=80 left=-120 width="800" height="600"}

::: {style="position:absolute;top:15%;left:59%;"}
<span style="font-size: 30px;">Magnitudes differ but same patterns<br><br></span>
<span style="font-size: 30px;">F<sub>seq</sub>(BGP) --- 0.6 - 1.9 Pg C y<sup>-1</sup><br></span>
<span style="font-size: 30px;">F<sub>seq</sub>(BCP) --- 0.9 - 2.6 Pg C y<sup>-1</sup><br><br></span>
<span style="font-size: 30px;">F<sub>seq</sub>(1000 m) --- 0.4 - 1.1 Pg C y<sup>-1</sup><br></span>
<span style="font-size: 30px;">F<sub>seq</sub>(2000 m) --- 0.2 - 0.5 Pg C y<sup>-1</sup><br><br></span>
<!-- <span style="font-size: 30px;">F<sub>seq</sub>(BCP) up to 6 times higher than fixed sequestration depth studies<br><br></span> -->
<span style="font-size: 30px;">Mixing --- 11-23% of F<sub>seq</sub>(BCP)<br></span>
<span style="font-size: 30px;">VMP --- 9-12% of F<sub>seq</sub>(BCP)</span>
:::

<!-- ## VMP and Mixing --- 21-34% to F<sub>seq</sub>(BCP) -->

<!-- ::: {style="position:absolute;top:15%;left:0%;"} -->
<!-- ```{r, Fseq estimations and % } -->


<!-- # df <- tibble(version = c('C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7'), -->
<!-- #              bgp = c(72,79,75,72,76,76,76), -->
<!-- #              mixing = c(15,11,14,17,13,13,23), -->
<!-- #              migrant = c(12,9,12,10,11,11,11)) -->

<!-- df <- tibble(Version = c(rep('C1',3), rep('C2',3), rep('C3',3), rep('C4',3), rep('C5',3), rep('C6',3), rep('C7',3)), -->
<!--              pump = c(rep(c('BGP','Mixing','VMP'),7)), -->
<!--              value = c(72,15,12,79,11,9,75,14,12,72,17,10,76,13,11,76,13,11,66,23,11)) -->

<!-- tab_df <- df |> -->
<!--   group_by(Version) |> -->
<!--   summarise(list_data = list(value)) -->

<!-- tab_df |> -->
<!--   gt() |> -->
<!--   gt_plt_bar_stack(column = list_data, labels = c('BGP','Mixing','VMP'), -->
<!--                     position = 'fill') #|> -->
<!--   # tab_options(table.width = px(500)) -->

<!-- ``` -->

<!-- ::: -->

<!-- ::: {style="position:absolute;top:15%;left:60%;"} -->
<!-- <span style="font-size: 30px;"><br><br></span> -->
<!-- ::: -->


## {{< fa check >}} Take-home message #3

- Sequestration of DIC<sub>bio</sub> not only in deep waters
- Using a fixed sequestration depth underestimate F<sub>seq</sub>(BCP)
  * CONVERSE F<sub>seq</sub>(BCP) = 2-3 > F<sub>seq</sub>(POC, 1000 m) 
  * CONVERSE F<sub>seq</sub>(BCP) = 3-6 >  F<sub>seq</sub>(POC, 2000 m) 
- VMP and Mixing pumps are important contributors to F<sub>seq</sub>(BCP)
  - 21-34%
- CONVERSE could be applied for the evaluation of mCDR strategies

# Perspectives {background-color="black"}

# Thank you ! {background-color="black"}
